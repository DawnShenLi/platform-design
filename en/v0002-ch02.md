2 Theoretical framework
=======================

This chapter deals with the theoretical framework developed to support
my investigation on platforms. Mine is a composite body of inquiry
conducted through active participation in building digital systems over
a period of some fifteen years. Some of those systems, which I came to
call platforms, have become successful, while some others vanished
almost as quickly as they were built. The following sections introduce a
series of concepts that clarify the underlying premises of my research
during the development of the projects that are presented in this
compilation thesis.

The chapter looks first at observations and then preconceptions. The
section on observations frames the literature used to build an
understanding of platforms, and the ethnographic and design toolboxes
they require. The section on preconceptions introduces the key concepts
that will help readers navigate the projects and understand the level of
finish and participation each of the cases has to offer. Thus while the
observations section looks at different theoretical views instrumental
in building an understanding of contemporary complex systems such as
platforms, the preconceptions section explores and discusses my own
framework. Evolving under the premise of incompleteness, long after the
publication of the various papers, this preconceived framework will be
articulated, challenged, and transformed.

<span id="anchor"></span>From networks to platforms
---------------------------------------------------

From a purely technical perspective one could claim that digital
networks are nothing but a series of computers (clients and servers),
exchanging information (via protocols) and storing the data (in
databases) for later use. This is however a very narrow definition of
how to look at contemporary systems. Clients are now pervasive, while
servers have been diluted with cloud storage. It is not only the
technology that has changed from a series of discrete artefacts into a
sort of continuum. The term ‘pervasive’ infers that technology is always
there, always-on, in our pockets, usually in the shape of a mobile
phone. Technology is no more a ‘window on a virtual world’ than it is an
axiom of the cloud’s brain that connects us permanently to a database.

People are now part of the continuum. We have redefined our role and
become one with the ‘distributed machine’ that the network has become in
recent years. We no longer interact with others using the system as a
vehicle, because the affordances (Gibson 1986, ch. 8; Gaver 1991; Fry &
Reas 2007, 554; Kaptelinin & Nardi 2012) of the artefact allow for
better interaction and integration.^[^1^](#fn1){#fnref1 .footnoteRef}^
Rather, we interact as part of the system—a regulated part that we often
call a ‘platform’, the underlying network of which is now diluted in the
cloud.

<span id="anchor-1"></span>In order to avoid a discourse determined by
dichotomies, in the following genealogy I instead emphasize the
historical transformation of terminologies and understandings of the
relevance of technology in the field of platform creation. It is my goal
to draw attention to a modality of design rather than to oppositions in
the existing ways of making technologies for people.

### From accessibility to democratization

The increased accessibility of communication infrastructures such as
telephony or the Internet is commonly referred to as ‘democratization’,
a process that Alexander et al. (1977, 73) studied through the
decentralization of the power in communities, while Ehn (1988, 247) has
looked at the more concrete example of the workspace with the
introduction of ‘computer artefacts’. The word democracy, from the Greek
*demo* and *kratos*, ‘may refer to the power (*kratos*: literally,
“grip”) of the *demos* in the sense of its capacity to act’ (Lane 2014,
55). *Demos* may both refer to ‘the people’ and ‘the common people’
(‘the many’ or ‘the crowd’). As Lane (2014, 87) mentions, it is an
ambiguous term, which is as much a weakness as it is a strength. This
duality leaves democracy a term that could refer to giving equal power
and rights to all levels of society, but equally to the power that the
many can exercise over the few. Democratization is thus a term I use to
talk about giving different levels of access to the public.

The relationship between technology and democracy can be seen from
different perspectives. On the one hand, better access to technology
increases the social debate and the participation of individuals in
governance (Sun & Barnett 1994), this means that there is a greater
chance for a democratic process to emerge in highly connected societies.
While Sun and Barnett’s study was limited to fixed telephony
communication networks,^[^2^](#fn2){#fnref2 .footnoteRef}^ others such
as Cubitt (2014) mention that data network developments are important to
democratic participation. It could be argued that if this bond between
technology and the democratic process gives more people greater access
to fundamental communication technologies, it is an act of democracy.
Not only is access relevant, so is the possibility that certain
technologies offer for knowledge creation. Open-source and free
software, together with the more recent hardware hacking techniques and
the open hardware licence models, establish a ‘new set of opportunities
for democratization of knowledge’ and ‘develop new forms of
technological citizenship’ that even affect the production of
industrialized products (Powell 2012).

We can find a counterargument in the work of the philosopher Andrew
Feenberg on democratizing technology (2001). From a neo-Marxist
perspective, Feenberg defends the view that we should find a way to
rationalize technological development so that it can integrate
alternative societal views and values. His early work on the topic might
lead the reader to believe he is against the idea that spreading
technology as much as possible is an act of democracy; however, in later
publications his point of view is clearer. Thus in his 2010 book
*Democratic Rationalization* he argues that the development and impact
of technology are ‘intrinsically social’ and that democracy has to be
extended into the ‘technically mediated domains of social life’ for it
not to disappear (Feenberg 2010, 6).

Democratization, filtered through Feenberg’s discourse, is linked to
accessibility, which refers to making the technology present in the
contexts where it is needed. Empirical data suggests that accessibility
could be increased by letting users own the infrastructure, if only
partly, through hybrid ownership and exploitation schemas (Baig et al.
2016; Saldana et al. 2016). While accessibility deals with ownership,
democratization refers to the user’s rights to influence the creation of
the technology per se. Contemporary discourses on design and technology
suggest that our approach to democratization should see the making of
horizontally governed communities of limited size (Alexander et al.
1977; Papanek 1988).

The axis of analysis for accessibility and democratization raises an
interesting conflict that platform designers will have to solve: a
distributed community will have a harder time accessing economies of
scale, as its power of negotiation in the current market economy will be
reduced. Which balance can be struck between community size and
technological scale that would generate an economically sustainable
platform? On the other hand, platforms exist that do not operate with
this distributed paradigm. How can ideas of accessibility and
democratization be operationalized on existing online platforms such as
Google or Facebook, where the number of users is what matters? Expanding
the question to a global scale, is a distributed architecture really a
viable solution for a fully networked society?

### From distributed networks to interdependent actors

A different take on democratization comes from Saldana et al. (2016). As
engineers, their take on the democratization of access to different
types of networks is to open up for the creation of a whole new range of
services based on alternative economic and ownership models. The most
relevant aspect here of the Saldana study of technologies used in remote
locations or places where it is not financially worthwhile for large
corporations to offer access to digital data networks, is how a variety
of stakeholders will intervene and share the purchase, deployment,
maintenance, and exploitation of different networks. Furthermore, such
deployments allow for different business models as well as shared
ownership mechanisms that distribute the power of the networks
differently. When looking at a deployed technology in this way, we give
it an agency similar to human agency. This shift in the understanding of
agency is often referred to as the ‘material turn’, ‘new-materialism’,
or the ‘ontological turn’, depending on the school of thought
(Pellizzoni 2015, 72). The ‘material turn’ refers to the analysis of
complex assemblages of non-humans and humans, where the latter are not
privileged in relational terms.^[^3^](#fn3){#fnref3 .footnoteRef}^ This
combination of different types of actors, their relations with one
another, and the maps of connections traceable by researchers when
describing them, is also the central idea in actor–network theory as
coined by Bruno Latour and others (Law 1992; Latour 1996, 2006).
Actor–network theory has been applied to a wide range of different cases
where technologies—as non-human actors—share agency with humans.

In an article on ‘The agency of assemblages and the North American
blackout’, the political scientist Jane Bennett (2005) looks at systems
as an assembly of operators (humans) and machines (non-humans), where
the decision-making is distributed among the two groups of stakeholders.
According to Bennett, a network is an assembly of hubs, switches,
servers, but also IT technicians, users, and service providers. The
governance of the network is controlled by a collective intelligence, in
which machines as well as humans make decisions at the speed of light.
The networks analysed by Saldana et al. (2016) have a type of agency,
due to the different nature of the participants in the everyday
management of the systems, that differs from more mainstream networks.
Saldana et al. suggest that people—understood in a very broad sense to
include end users, small-scale entrepreneurs, and local authorities—not
linked to large telcos can make use of state-of-the-art technologies to
create their own communication infrastructure. Off-the-shelf,
commercially available technologies are good enough to support the
creation of new situations where accessing online products and services
is somehow more democratic.

Seen from Bennett’s perspective, contemporary systems are techno-social
and/or sociomaterial, not only made of wires and bits, but of flesh and
blood and social exchanges. Automated mechanisms are interwoven with
humans in complex feedback loops where decisions are made on the spot on
the basis of information coming from mixed media systems. Her study of
the North American blackout in 2003 reflects upon the issues of
decision-making, human–machine assemblies, and spatial–temporal changes.
When applied to the idea of building a network in an underprivileged
area, the concern of Saldana et al., the social aspect takes on an even
more complex dimension, where local communities, represented by
political parties, could introduce socioeconomic agendas to the
governance of systems that are already commanded by technology and the
technological culture.

From a technical perspective, the ethnographic data captured by Saldana
et al. (2016) shows how the Internet is indeed a network of networks. In
that sense, we find ourselves faced with a distributed technical network
with different models for sustainability and governance depending on the
case. From an actor–network theory perspective, what we see is a series
of relationships between actors: users, entrepreneurs, networking
machinery, the electricity network, and even the geographical landmarks
that determine the distributed nature of the technical network.
Actor–network theory becomes a tool with which to trace complex
situations in which many interrelated actors coexist, who by virtue of
their agency all contribute to make the actor–network what it is.

### From embedded systems to the IoT embodied

The literary scholar N. Katherine Hayles (2009) goes beyond Bennett’s
global view of systems in her analysis of radio-frequency identification
(RFID) technology as the stepping stone to largest platform-to-be of
all: the Internet of things. RFID is a system based on tags that can be
embedded into almost anything and readers that can identify the tags at
a distance by sending a radio signal. RFID tags provide a way to equip
things with unique identifiers—a sort of passport number—and this
renders a new kind of agency to things. It is no more *a* thing, it is
*the* thing we are talking about. Unique identification is part of human
nature (though not only ours, as animals also have it) that we can now
transfer to inanimate objects. For Hayles, a thing is a smart device
with some sort of distributed computing capabilities. RFID is
distributive by nature and makes objects into things. This brings with
it a transformation of our understanding of the world: we are moving
away from an understanding built on the triad of human–animal–machine to
one filtered through the lens of a new triad of human–animal–thing.
Hayles’s definition of thing is in this respect of central importance.
Things are a new type of object with double-layered properties, for they
have a physical reality but also a virtual one, and both do not always
stick together.^[^4^](#fn4){#fnref4 .footnoteRef}^ Things are made of
‘sensors, communicators, and actuators’ (Hayles 2009, 57), in which the
communicators refer to the ‘new’ capability that things have to talk to
other things within networked systems. Communicator is thus an
interesting label when referring to an off-the-shelf smart device that
will give off-the-shelf sensors and actuators the ability to exchange
information with other sensor–actuator systems within the same network.

The promise of Internet-working, communicating set-ups does not stop
there. Using this technology, devices connect to other devices outside
their networks of origin; data is collected by third parties; and
information is extracted from patterns and events, to be harvested from
data flows (Brody & Pureswaran 2014). The embedded sensor–actuator
systems—electronically enhanced apparatuses that could range from a
wearable computer in our pocket to a weather monitoring network covering
a whole region—when augmented with Hayles’ communicators, constitute the
things in the Internet of things. While the power of embedded systems is
such that they are always on, now they will always be connected too. In
the mid 2000s, the legal scholar Lawrence Lessig (2004, 297) fantasized
about having always-on systems that were always connected. Pushing it
even further, the science fiction author Bruce Sterling coined ‘SPIME’
to describe manufactured objects with an informational layer so rich
that they would be referred to as ‘material instantiations of an
immaterial system’ (2005, 11). Less than 15 years later, with the IoT
being implemented in live scenarios, always-on, characterized by layers
of meta-data systems, is already spreading all over the world. This is a
new reality, a distributed material turn where anything and anyone can
have an always-on virtual representation in the form of Hayles’s
human–animal–thing triad.^[^5^](#fn5){#fnref5 .footnoteRef}^ The two
predominant computing paradigms of pervasiveness (always with you) and
ubiquity (embedded everywhere) have gained a new definition—embodied
everywhere. Technology is embedded in the body; the thing becomes one
with the living being. According to Redström (2001, 213), take the
concept of ubiquitous computing to the extreme and everything we do can
be considered writing (as in writing data to the system). When carrying
around IoT-related technologies, we are writing all the time, when we
move, when we speak, or when we touch other things.

Looking deep into this conglomerate of flesh and bits, wires and social
exchanges, we can ask ourselves if it is this hybrid nature that makes a
platform. Is IoT a platform? If so, what is the role that humans will
play in it it? Who owns the platform—the users and their devices, or the
developers and their services? How does authorship work on a platform,
and who owns whatever is produced on it? Some of these questions can be
answered by further exploring the existing literature on the topic,
while some others can only be given more speculative answers as they are
still unknown. I will start by exploring the meaning of the word
platform.

### From technological switches to intermediary exchange

The term ‘platform’ has been used broadly as part of a discursive work,
mainly because of the different connotations of the word, to accommodate
all sorts of points of view. A platform can be understood as something
technical, as a place to address an audience from or as a moment of
opportunity. It even has a figurative connotation, becoming a
metaphysical space ‘for opportunity, action, and insight‘ (Gillespie
2010). It is Gillespie who offers the best description of what a
platform has become in contemporary history: ‘The term “platform” has
emerged recently as an increasingly familiar term in the description of
the online services of content intermediaries, both in their
self-characterizations and in the broader public discourse of users, the
press and commentators.’ Platforms grow on top of networks, and more
specifically data networks that take advantage of online content
brokers. Gillespie studies YouTube, a system that does not create
content itself, but collects content created by users, and curated by
means of machine-controlled algorithms characterized by user
preferences.

The term platform is both specific enough to mean something and vague
enough to work across multiple domains. Gillespie groups the different
meanings of the word into four categories: computational, architectural,
figurative, and political. As a computational term, it is ‘an
infrastructure that supports the design and use of particular
applications’. As an architectural term, it ‘describes human-built or
naturally formed physical structures’—it seems to be the combination of
the French terms ‘platte’ and ‘fourme’ which translates as ‘flat form’.
As a figurative term, a platform becomes a ‘metaphysical \[material\]
for opportunity, action and insight’. As a political term it ‘generally
implied a kind of neutrality towards use—“platforms” are typically flat,
featureless and open to all.’

To that common set of features, I would add the idea of community,
defined as a ‘realm of practice’ built on ‘connections uncovered in the
course of everyday experience’ (Feenberg 2007, 28). Platforms as
emergent systems can be born from a social innovation process, where a
community would foster the creation of a system to suit their needs, but
where there could also be a purely economic interest in their creation
as suggested by Plantin et al. (2016) in their analysis of Google and
Facebook. This idea of a dual origin of platforms can also be found in
Saldana et al. (2016) when looking at the different types of
socioeconomic networks that can be formed on top of a technical
communication network: some of their cases are bottom-up (more
community-centric) while others are just clever adaptations of business
models of more traditional corporate systems to accommodate a situation
or need. Gillespie (2010, 350) hints at the idea of community when he
explains how a platform ‘suggests a progressive and egalitarian
arrangement, promising to support those who stand upon it’. He takes
this line even further by analysing what makes computational systems
become computational platforms. Specifically, he says that a
computational platform is the technical base ‘upon \[which\] other
programs will run’; but what makes them platforms is not that ‘they
allow code to be written or run, but because they afford an opportunity
to communicate, interact, or sell’. This community aspect is then linked
to the idea of the platform as a political term. Communities are
governed by social contracts (terms and conditions or codes of conduct)
and so is a political platform; what it takes is a set of beliefs to
build on (Gillespie 2010).

Again, Gillespie explores in depth some of the relevant attributes of
platforms, of which the ‘featureless’ property of a platform seems to be
one of its strengths: a platform ‘is anticipatory, but not causal …
implies a neutrality with regards to the activity’ (2010, 350). This
statement raises a series of questions regarding the relationship
between neutrality and features. Do not platforms that cover the same
design space compete in terms of features (whether technical or any
other form) in order to survive? Is that neutrality just a temporary
aspect, seen only during the establishment of a platform? To what extent
is a platform such as Facebook or Google neutral? Is there a difference
between large platforms and small ones?

The question of neutrality is addressed by Feenberg (2010, 6) when he
states that ‘modern forms of hegemony are based on a specific type of
technical mediation’. In the current state of affairs, technology serves
specific interests rather than the interests of ‘people’, and therefore
fails to support democracy unless a radical change is effected.
Ultimately, Feenberg raises the question of whether technology, by
definition, can be democratic. He suggests that unless there is a change
in how technology is pursued, democracy will simply fade away. It is a
catch-22 situation, as in order to support democracy we need a more
democratic way of creating technologies. He concludes with a message of
hope, though: ‘Technology can deliver more than one type of
technological civilization. We have not yet exhausted its democratic
potential’ (Feenberg 2010, 29). Perhaps, as Powell puts it (2012),
‘hardware hacking’ with its ability to influence the production of
industrial products, can be the radical move that Feenberg hints at to
make technology more democratic.

### From program to accountability

For software developer and entrepreneur Marc Andreessen, known as the
co-author of the Mosaic Web browser among other things, a platform is
something that can be programmed, and if it cannot then it should not be
called a platform. His definition comes very close to Gillespie’s
‘computational platform’, as we have seen. On the other hand, if one
reads Andreessen’s 2007 article ‘The three kinds of platforms you meet
on the Internet’ and follows his argument in depth, it is evident he has
a clear vision of what a computational platform should be in terms of
its offering for—mainly—developers. But then it is a statement made by a
person devoting his time to the creation of online programming
platforms. This idea of programmability as the basic property of
platforms has permeated a more scholarly discourse too. For example, the
Dutch researcher Anne Helmond, when looking at the infrastructure of
social media platforms, describes ‘platformatization’ as the
introduction of programming capabilities on the web, and more
specifically the ‘programmability of social media platforms for the web’
(Helmond 2015).

Andreessen (2007) represents a far more technocentric discourse, as he
is obviously addressing an entirely different audience than the authors
considered thus far. He is worth mentioning, though, to draw attention
to the fact that there is a whole group of potential stakeholders who
have a clear idea of what constitutes a platform and what they expect
from a platform design process. For designers, it is important to figure
out how to approach the needs of this kind of user, who, following
Andreessen, tend not to waste words on the ethical aspects, which
according to Feenberg (2001) we should always take into account when
dealing with the design of new technologies.

Contemporary research efforts under the aegis of the European Union are
already looking at how systems should be designed to take ethical
aspects into account. For example, the EU research project ‘Virt-EU’ is
looking at the issue of citizen rights in the management of personal
data. At an official project event at the IT University in Copenhagen on
12 January 2017 *(Virt-EU Kick Of*f 2017), Alison Powell and Alessandro
Mantelero introduced the audience to the need to include ethical
considerations in the design of IoT systems.^[^6^](#fn6){#fnref6
.footnoteRef}^ Powell discussed our position as citizens in this seismic
sociotechnical shift by saying that ‘technologies of datafication, that
are transforming our life more and more into data, create new dynamics
and new relationships that can affect the way we are citizens … A good
citizen per these processes, is the one that produces a lot of data’
*(Virt-EU Kick Of*f 2017). There is room for people dealing with the
idea of datafication of our citizenship. And here is where the ethics
come in. Powell advocates the re-examination of the principles of
‘virtue ethics’. She thinks that they will come from the people who are
deploying the technologies. In her Copenhagen speech, Powell introduced
the term ‘virtuist’, a person who proposes a series of virtues so that
people flourish, and will be the bedrock of a good society.

Mantelero, both at the IT University event *(Virt-EU Kick Of*f 2017) and
in an earlier paper (2016), focused instead on the legal aspects of data
acquisition, treatment, and protection. At the heart of his Copenhagen
presentation was the assessment of risk. In general terms, it is an
element that has been present since the advent of data protection
regulation. It is based on the idea that data collection created an
awareness of the risk of social surveillance, and therefore the
regulatory bodies had to put in place protection for individuals. His
goal is to study the IoT communities that exist and look at whether the
communities’ values can be applied to the law and vice versa.

In her essay ‘Deadly Algorithms’ (2014), Susan Schuppli addresses the
concept of algorithmic accountability, and explains how ‘decision-making
by automated systems will produce new relations of power for which we
have as yet inadequate legal frameworks or modes of political
resistance’. She does not seem optimistic about our chances of
identifying valid governance models that will tackle the issue of
sociotechnical assemblies making potentially deadly decisions for us.
Schuppli infers that society has to undergo a significant transformation
in order both to enable these technologies and to establish mechanisms
of control, and that will require of a greater level of participation.
She asks an open question about the kind of social assembly capable of
controlling these advanced technological developments, especially in
situations where the information itself may be kept from the public for
‘reasons of national security’. Powell and Mantelero, in looking at
sociomaterial assemblies, are not only saying that we the public become
data that feeds a series of supranational intermediaries that profit
from that data, but also that associations of people—communities—are
currently unprotected as a group. While individual rights seem to be
covered by contemporary legal frameworks, group rights are
not.^[^7^](#fn7){#fnref7 .footnoteRef}^ By extension, sociomaterial
assemblies are not covered by the same regulations that protect
individuals. Powell and Mantelero’s thesis is that we should support the
autoregulation of assemblies by including the consideration of legal
values when designing platforms. Their work is more recent than
Schuppli’s, and they seem to be looking for solutions to the problems
she describes.

### From usability to participation

Björgvinsson et al. (2012) define ‘Things’ by presenting the term in
contrast to the traditional industrial design goal of the production of
objects. The ‘design community \[has to\] move from designing “things”
(objects) to designing Things (socio-material assemblies)’ (102). In
order to construct their own view on the topic, they find that the
‘etymology of the English word “thing” reveals a journey from the
meaning of a social and political assembly, taking place at a certain
time and at a certain place, to a meaning of an object, an entity of
matter’ (102). In a way, the concept of Things reclaims the social
meaning of things, creating a new super-term that includes both the old
and new etymologies in one. This redefinition of the term should be
contextualized within the general discourse of how designers should
engage in co-creation processes, addressing societal challenges through
the hands-on iterative processes where prototypes are created. Their
move from things to Things is directly connected to the idea of having
to move from designing tools to designing platforms. Designers, they
argue, should consider the sustainability of the design and think beyond
the specific project ‘toward future stakeholders as designers’
(Björgvinsson et al. 2012, 102). This they define as ‘infrastructuring’:
a design process that focuses on the building blocks conforming a new
complex system, understood as a amalgamation of products and services
for stakeholders to put together. Infrastructuring has a strong element
of participation in what is seen as a situated and continuous design
process, hence the reference to the cultural formation of Things. The
question is whether designers can follow this approach, and whether
there are any methodological tools to encourage or facilitate
participation.

One possible approach would be to use ‘sustainable’ human–computer
interaction as presented by Raghavan and Pargman (2017). Their
suggestion is to use ‘disintermediation’—the redesign of systems to
remove intermediaries—as a way to simplify access to products and
services, but also to simply make platforms cheaper. It has to be
understood that not all intermediaries in assemblages are bad. The
‘punctualizations’—or process of representing a whole network of
resources with a single node—as described by Law (1992) can be
understood as adding an intermediary between the actor and the
resources, offering simplicity in exchange for
control.^[^8^](#fn8){#fnref8 .footnoteRef}^ An example of such
disintermediation is the case described by Law and Mol (2001) of the
Zimbabwe bush pump, where the design of the pump was left open so people
could use it in whatever form they considered convenient. In that case,
the disintermediation is clear in the fact that anyone could make their
own pump from a generic model, which with a little tweaking could be
adapted to meet any demand; it would not be easier to use, but easier to
‘hack’. By contrast, Akrich (1992) presents the case of solar-powered
lamps, where a complex system was ‘punctualized’ into what at first
seemed to be a very simple technical solution. Yet it turned out to be
simple only at a superficial level. Due to the specific punctualization,
in this case the kind of connectors between lamp and battery and the
fixed length of cables, the lamp was hard to install and not always
usable. Here, the attempt to prevent users from accidentally damaging
the equipment or themselves by the use of standardized-yet-proprietary
designs made it hard for local electricians to install and maintain the
technology. This is the opposite of a disintermediated process—an entity
designing for a user group failed to produce the exact design needed,
and since it was not possible to adapt it in the field, the design did
not work as wanted.

These two examples speak to design accessibility, agency, and the
pervasiveness of technology. Infrastructuring as a process of ‘aligning
socio-material public Things’ (Björgvinsson et al. 2012, 108) is about
enabling participation in design, and that is how this concept of
designing things links to platform design in a seamless way. The
featureless, generic character of platforms, which Gillespie (2010)
talks about, is of central importance in order to facilitate a
sufficiently open and continuous design process. For the newly created
system to be a thing, it cannot be too specific. Yet if pushed too far,
its generic qualities may become standard, with little or no room for
local decision-making or adaptation.

One method of addressing the potential of a democratic process on
platforms could be the implementation of feedback mechanisms by design
to allow continuous participation. Platforms, because of their
technological component, are able to implement feedback loops. Wiener
(1989 \[1950\], 61) describes feedback as a ‘method for controlling a
system by reinserting into it the results of its past performance’; it
is a ‘complicated process of discrimination, regulated by the central
control as a logical or mathematical system.’ As a matter of fact,
Wiener describes ‘policy feedback’ as the type of feedback that will
produce either a conditioned reflex or a learning process (1989
\[1950\], 33). Feedback is an important part of infrastructuring, as is
learning. Wiener’s ideas are exportable to any kind of (non-)human
assemblage, and therefore contribute to the idea of continuous change
through participation that should command the creation of things.
Participation is therefore not important only during a system’s
co-creation phase, but also once the platform has been deployed. The
possibility of having meta-conversations on platforms where even the
nature of the platform is questioned opens up for the creation of codes
of ethics and community governance models, which might challenge the
original intentions of the platform builders as to how discourse should
be handled. This application of the cybernetics concept of the feedback
loop raises other interesting questions once agency is passed to the
non-human component of the assemblage. If, as Rouvroy (2013) said of
algorithmic governmentality, artificial intelligence (AI) is constantly
running on feedback loops that modify non-human responses in real time,
how would non-human feedback loops be weighed against the human ones?
They would presumably challenge some of the human roles in the
assemblage, such as the ability to curate or highlight aspects that
might be considered of greater relevance to users. Boden (2017, 31)
suggests introducing heuristics by design to the assemblage so that the
system anticipates in which cases the human or the non-human should
count first in the event of a conflict. Such systems would affect
participation and governance, potentially shifting them from being
discourse-driven to being purely data-driven. Some of these challenges
will be explored later, while others are part of the current discourse
of the agency of actor–networks, and thus are already detailed in the
literature.

Preconceptions
--------------

Preconceptions, the starting point of the present study of platforms,
are germinal ideas that will later be challenged and augmented by
experience. Initially, I took technological development to be a process
of zooming out from the micro scale of a tool to the macro scale of the
role played by that tool as something bigger and
generalizable.^[^9^](#fn9){#fnref9 .footnoteRef}^ I started with the
idea that tools could grow organically into platforms through the
addition of other processes and tools. One of the cases I am still
working with, the co-creation in 2005 of the Arduino platform,
encouraged me to believe that platforms could be constructed slowly and
sustained easily. This preconceived idea of how platform creation could
be was based on a single experience, and therefore detached from other
realities. Dealing with platforms today, in the context of the market
economy, demands that one always look at the metrics, constantly
checking how well one’s platform performs in comparison to others in the
same sphere. It is an exercise in numbers: creating tools to improve the
numbers, and constantly analysing what others have done to obtain better
results. Making things measurable is an end in itself in the market
economy, and is something I have learnt in the creation of the Arduino
company, itself an evolution of the Arduino platform. Metrics are the
thresholds in the measurements that trigger further events. A company,
like a platform, is run by a simple algorithm executed on a
socioeconomic assemblage with metrics we check at all times to ensure
that its behaviour and performance are the expected ones. The larger the
system, the more relevant it becomes to design algorithms to direct this
expansion effectively.

My preconception was to study assemblages from the point of view of
their size, understood as expansion, and their performance, and that is
what I will present here. There is no linear way to address the
classification of systems, except perhaps by the total size of the
assemblage. That gives us a scale that ranges from tool (the smallest),
via toolbox, kit, and platform to infrastructure (the largest), as is
presented—in order—in the following section. There is an opportunity to
enact the power that comes with size if the number of users of an
assemblage is not too great, but it might not be appropriate to invest
the resources to develop a platform to support it, which in turn might
also limit its ability to expand, its accessibility, or even its shared
governance. As will be seen, size analysis is not the only factor to be
considered when designing platforms.

### <span id="anchor-2"></span>Tools

According to the *Oxford English Dictionary*, a tool is ‘a thing used to
help perform a job’ or ‘a device … used to carry out a particular
function’; definitions that are applicable to all of sorts of artefacts,
material or immaterial, and therefore software and even
processes.^[^10^](#fn10){#fnref10 .footnoteRef}^ The psychologist James
J. Gibson (1986, 40) gives his own definition of a tool, and summarizes
in a sentence how important tools are, to the point where having access
to tools may have affected our evolution: ‘Tools are detached objects of
a very special sort. They are graspable, portable, manipulatable, and
usually rigid … humans are probably the only animals who make tools and
are surely the only animals who walk on two feet in order to keep the
hands free’. Although research has shown that other species do use tools
(Furlong et al. 2008), it is still correct to say that humans are far
more proficient in using tools. This superiority in the use of tools
happened due to our ability to acquire language (Stout & Chaminade
2009).

Pelle Ehn (1988, 392), a specialist in interaction design, in
considering Ole Thyssen’s categorization of human instruments,
distinguishes between ‘body, language, social institutions and tools
proper’. In a sense, when I talk about tools, I am referring to what Ehn
describes as ‘tools proper’—the physicalizing of work and knowledge.
Tools are ‘designed, constructed, maintained, and redesigned … design
and use of tools in this sense is interrelated to the other instruments:
our bodies, our languages, and the social institutions we live in’. Ehn
goes further, drawing on Heidegger, Marx, and Wittgenstein to construct
his theoretical apparatus. He looks at the relationships between our
understanding of the world in practical terms, our relationship with
labour, and the use of language games. He believes that all three
approaches find the practical uses of tools to be fundamental to human
practice. When we have the skill to handle it, a good tool, in Ehn’s
eyes, becomes an extension of the body: ‘it is transparent to us;
something that lets us have focal awareness on the task or on the
material we are working with’ (1988, 393). Later in his career, Ehn
moved on to investigate the process paradigm (Björgvinsson et al. 2012),
to which I will return later.

When combined, tools tend to bear out the saying that the whole is
greater than the sum of its parts. For example, while a hammer can be
used to drive in nails and a burin can be used to engrave wood, hammer
the back of a burin from the wrong side of a plank and it is possible to
punch out nails without further damaging the wood. By using two tools
together, we enhance them by adding new functions. Tools do not need to
be physical objects. They can be found in other areas. In legal terms,
for example, a rental contract is a tool used to enforce a certain
relationship between the signatories. While still concrete in language
terms, a contract is abstract since it does not affect the physical
world through direct interaction with it. There could be a contract to
dig a well, but the contract is not the one doing the actual digging.
Language-wise we still refer to it as a tool that operates in law, which
in the end refers to established relationships among humans, based on
custom.

There are other non-physical areas where we can find tools. For example,
a software tool could be defined as a piece of software used to perform
a specific task in the same way we define a physical one. Examples of
software tools are executable programs to operate a fast Fourier
transform, software to edit video, or templates for accounting
spreadsheets valid in a certain country. For Ehn (1988), computer
artefacts, whether hardware plus software or only software, are tools;
however, unlike the other areas, they have a very specific field of
application, as they should be, according to Ehn, the ‘tools of
craftsmen’ (1988, ch. 17). If computer artefacts are ‘tools of
craftsmen’, do they then cease to be accessible to everyone? Were other
tools, like language, initially meant to be for craftsmen only, only
over time enlarging their target audience? And if so, to what extent has
the general adoption of computers in every area of contemporary society
changed this relationship?

Ehn’s linguistically oriented argument might seem dated. Since then, the
sociology of technology has taken a ‘material turn’—a turn that accords
material things the same weight as humans in assemblages (Pellizzoni
2015, ch. 72). Some of those things are computational materials that are
run by software, derived from a more abstract construct—algorithms.
Algorithms, as presented by Dourish (2016), are ‘materialized’ as a tool
or tools in the form of one or more executable software packages (or
even parts of executables). Some of the tools’ properties include the
ability to alter agency through feedback loops, which allows them to
respond directly to the environment. There is a clear difference between
such a tool, which is context sensitive, and for example a hammer.

By talking about problematizing algorithms, Schuppli infers that we need
to figure out new ways to think about the algorithmic aspect of software
tools. As she says, we have ‘insufficient collective understanding as to
how … decisions \[are\] made’ and how they bring new power relations
‘for which we have as yet inadequate legal frameworks or modes of
political resistance’ (Schuppli 2014). A new world unfolds in which
control is executed through obscurity, where the lack of understanding
about how technology works makes people into pawns to be controlled,
turning the algorithm into a mechanism of
control-by-closeness.^[^11^](#fn11){#fnref11 .footnoteRef}^ Are not
computer tools, apart from extensions of the body, also systems of
control? While Schuppli’s example is extreme in terms of the topic it
deals with—the killing of humans by machines—the idea of
control-by-closeness can be extrapolated to other fields. In her lecture
on ‘Algorithmic Governmentality and the End(s) of Critique’, Antoniette
Rouvroy (2013) explains how some of the deep learning algorithms are not
only impossible to comprehend—since they build their own categories and
decision mechanisms—but also impossible to criticise, since we can never
know how they classify events. Besides, the algorithms will never be
wrong; they will simply adjust their thresholds upon the arrival of an
event. In a way, algorithms can be closed because of intellectual
property limitations determined by their creators, or they could be
simply impossible to comprehend, which would make them inadvertently
closed.

The idea of being closed can be compared to the concept of
punctualization, because of the way it is manifested. If something is
closed, its inner mechanisms are invisible to us and the black box
paradigm applies: we know what to expect, but do not know how it will
happen. In a similar way, punctualization consists in hiding a process
from us due to its complexity, the frequency of its use, and so on. When
something becomes ubiquitous and its complexity vanishes from sight, it
goes through punctualization. This concept can be better understood by
looking at the evolution of operating systems. In his essay ‘In the
Beginning…Was the Command Line’, Neal Stephenson (1999) presents his
personal journey between operating systems over the course of several
years. He introduces the idea of moving from the command line interface
(CLI), where all commands have to be entered by typing their names in a
text box, into graphical user interfaces (GUIs) where most interactions
are within a two-dimensional visual interface. Contemporary operating
systems have gone through punctualization, whereby the GUI has become
the predominant interface, or ‘system of metaphors’, with the different
tools in the system. This hides the complexity of the artefact and makes
it more accessible. While Stephenson should be considered a computer
craftsman, his analysis is very pragmatic. He explains that computers
are now common tools and that the operating system is also a tool, over
and above which we have other tools that allow people to perform certain
tasks in satisfactory ways. Stephenson’s example presents a process that
could be called ‘toolification’, creating tools out of more complex
systems either by zooming out (punctualization) or because of the
obscurity (closeness) of the tool’s inner workings. This process invites
the creation of tools for almost any purpose by mashing up different
tools and punctualized systems.

The introduction of computers in the workspace as well as the home, and
the different factors associated with it, including the operating
system, peripherals, drivers, applications, malware, and so on, usher in
a whole new understanding of the concept of the tool. Ehn (1988, ch. 16)
has a whole discussion about the relationship between the tool and the
user, and whether a computer should or not be considered a tool. I
believe this has to do with the fact that tools—according to Marx and
other philosophers mentioned in Ehn’s book—are strongly linked to
labour. The actor–networks described in the various projects I was
engaged in imply some sort of digital labour. For example, the SandS
project was meant to involve technicians installing connected kitchen
appliances, while the PELARS project augmented teachers’ work
situations, and the article on the indoor location system reflects the
configuration and installation of the artefact at a home (by a
technician). And while indirectly addressing the topic of labour, I am
more interested in the idea of the tool as one element in a larger
sociomaterial ecosystem. While Ehn in the late eighties defended the
idea that computer artefacts should be designed as ‘skill enhancing
tools for production of good use quality products and services’ (1988,
407), today such an ambition needs to be differently managed. Ehn also
warned against the ‘tool’ labelling, since as tools, ‘computers alienate
our lives’ (1988, 408).

When Ehn wrote his book on the topic of ‘work-oriented design of
computer artefacts’ in 1988, computers were understood as generalizable
machines that could execute many different programs—simultaneously or
not—to perform different tasks. Thirty years later, computation has been
reduced in size and multiplied in performance (and pace) by several
orders of magnitude, while becoming so inexpensive that we now have
single purpose computers, even if the same machine could be used in many
ways. The specificity of purpose makes the computer a tool. Hence,
paradoxically, due to its abundance, the generic machine is being
toolified.^[^12^](#fn12){#fnref12 .footnoteRef}^ Computational power is
boxed into microcontrollers and microprocessors, two distinct types of
integrated systems in which structural differences are blurred as
technology advances.^[^13^](#fn13){#fnref13 .footnoteRef}^
Microcontrollers and dedicated processors allow for this new typology of
single-use computers, which are different from the computer artefacts
Ehn wrote about. Toolified computers are also growing in number,
facilitating paradigms such as pervasive computing and ubiquitous
computing. The multiplicity of single-use machines requires different
human–computer interfaces to the ones presented by Ehn. Additionally,
our technocentric society has developed computer-based tasks or ‘crafts’
that go far beyond the labour he described. As a result, one might say
that computers have gained the right to be considered tools. Or, using a
concept proposed by Ehn, computers have gained a certain ‘toolness’,
defined as the ultimate value of a tool. Toolness is described as some
sort of contextual affordance or increased contextual capability to
perform a task, because ‘tools do what we mean, not what we say’ (Ehn
1988, 403). It is in this respect important to relate this to the
contemporary mindset of ‘smartness’. While toolness represents
intentional control, smartness or intelligence represent automation.
‘Autonomous machines are intellectual tools, run by themselves on the
basis of an internalized model of some phenomena in the world’ (Ehn
1988, 399), so that an example of autonomous machine is, for Ehn, the
clock—‘Computers are autonomous machines, only much more general’ (401).

Further problematizing the concept of smartness, Ehn critiqued
artificial intelligence (AI), arguing that at the level of tool it might
not be what we need to better perform a task. He sees a conflict between
toolness and intelligence, between control and automation. However
‘intelligent tools may be designed to strengthen rather than weaken the
user’s control’ (Ehn 1988, 404). Considering the state of the art and
the development of AI as described the cognitive scientist Margaret
Boden (2017), I would enlarge on Ehn’s view of computer artefacts
lacking toolness, but cannot agree with his understanding of a tool as
being something without intelligence of its own, where the human has to
be in control. Humans may sometimes be in control of the process, or
just in control of the outcome, or sometimes in control of both. This is
made clear in the Schuppli’s examples (2014), Stephenson’s toolification
of operating systems (1999), or Dourish’s reflections on about
algorithms and AI (2016). Therefore, the concept of toolness should be
upgraded if it is to describe the qualities that make something a tool
in contemporary terms, including aspects such as AI and punctualization.
Automation, instead of imposing a problem on control, should be seen as
a way to enhance existing tools and to create new ones using embedded
technology and intelligence.

In sum, tools offer intentional, direct solutions to immediate problems.
Tools can be complex in nature, or the result of a fairly complex
development process. Tools, redefined to be part of assemblages of
humans and non-humans, could include feedback mechanisms and have an
agency that allows them to perform new types of tasks that require
computation. Tools’ main feature remains to hide the complexity of an
operation, helping us perform something effectively with as little
effort as possible.

### <span id="anchor-3"></span>Toolboxes

‘The cops confiscated all my equipment … if you want this done tonight,
I need hardware’, says Elliot in the ‘h1dden-pr0cess’ episode of the
extremely popular television drama series *Mr. Robot* (2016). Elliot,
the main character, needs a laptop, a computer scanner, a printer, some
paper, a series of burner phones, and a piece of software to perform a
social engineering hack, where he will obtain the location of a mobile
phone he has been asked to find. His toolbox is made of hardware and
software, reusable and disposable materials.

A toolbox is, by definition, a collection of tools and fungibles that
allow us to perform a series of actions of a certain kind. The
carpenter’s toolbox will always include hammers, chisels, screwdrivers,
screws and nails, a pencil, and so on, and while some of the materials
are single-use, most are reusable—the tools. The carpenter’s expert
knowledge is what makes the combined function of the tools more than
just the sum of their functions. Unlike kits, which will be described
later, toolboxes do not need instruction manuals, since they are built
on expert or experiential knowledge.

As Mellis et al. (2013) note, ‘even users expert with a particular
toolkit may remain locked in by its constraints’. This means that a
toolbox (a toolkit for Mellis et al.) presents some limitations because
of the affordances of the tools, and also the users’ knowledge.
Blikstein and Sipitakiat (2011) introduce the idea of a ‘breakout model’
in electronics toolboxes, which is closely related to the way the
Arduino platform was conceived in the first place: users build systems
using off-the-shelf components using the Arduino board as the digital
controller of the various peripherals, and to permit users to do so the
boards are designed with as many exposed pins and processor peripherals
as possible. However, I cannot entirely agree with Mellis et al.’s
definition, as when they talk about ‘toolkits’ they sometimes refer to
the wider utility of a toolbox, yet also use ‘kit’ in the more targeted
sense that will be described later. Meissnet et al. (2018) do not make
this distinction either, and even propose a ‘meta-toolkit’ as a way to
produce toolkits adjusted to different contexts: ‘every toolkit needs
skilled “tweaking” effort to make it work in a specific setting’ (10). I
would argue that this mismatch between ‘toolkit’ and ‘kit’ is part of
the general lack of workable definitions in the field. On reflection, I
would say that the ‘breakout model’ gives an idea of what it takes for a
tool or toolbox to grow into a platform, having as it does much of the
featurelessness (Gillespie 2010) that technology needs in order to reach
as many as possible.

A toolbox is made of replaceable parts; as tools and appliances wear out
we add new ones. A toolbox is something you have even if you do not use
it at all times. It is waiting to be used. There are professional
versions, some with higher-quality tools, others intended to be used
once or twice. When transposing the idea of the toolbox to the
non-physical, it changes to some extent. For example, in the world of
software, it is not immediately apparent how to apply the idea of
disposability of materials. Software is made to be copied, backed up,
transferred, and the only feature that can make software disposable is
the technical obsolescence of software subsequent to the further
development of the computing machines or operating systems on which the
software runs. One could thus say that software, since it is attached to
the operating system, which by proxy is attached to a computer
architecture, has a materiality that makes it disposable. As will be
seen, this is further challenged by usage needs.

There are other scenarios in which toolboxes can be defined in the same
way in the world of software as in the physical world. I will present a
couple of cases to problematize this, looking first at computer
security, since it offers an analogy to the idea of disposable materials
in toolboxes, and then at software development kits. While I have barely
touched the idea of disposable software in my work, I do have experience
of working with the creation of software toolboxes such as the original
Arduino IDE or software suites for various operations in the fields of
installation, simulation, and maintenance.

When looking at disposable digital material, pretty good privacy (PGP)
software is a good example.^[^14^](#fn14){#fnref14 .footnoteRef}^ It is
software that ensures secure communication between two parties. In order
to make that communication secret, the parties have to exchange a series
of randomly generated numbers (keys) specially created for the session.
Another scenario is the keys used to identify secure service providers
online. The https protocol offers enhanced communication by means of
unique identifiers sitting on the servers, and those identifiers are
issued by third parties to ensure no other servers on the Internet can
be mistaken for the one you want to access. That unicity in the form of
a unique identifier is the equivalent to the single-use nail in the
carpenter’s toolbox.

While PGP stands for disposability, a software development kit (SDK)
equates to the reusable toolbox. While in software development SDKs are
referred to as ‘kits’, I consider them toolboxes: a series of software
tools designed to help construct software products in specific contexts.
There are SDK toolboxes for all sorts of devices. One example is Vuzix
glasses, an Android, powered, industry-oriented device similar to Google
Glass. Even if the device is programmed using the Android programming
language, which is open source, in order to compile and upload code to
the device one needs a special toolchain and development environment.
Another example is the Arduino IDE, the software that Arduino users need
to create the programs that will be compiled and uploaded to boards. The
Arduino IDE is generic in the sense that it allows for different
toolchains for various types of microcontrollers to be programmed with
it. In some cases, some end products can also be programmed using the
Arduino IDE: the Sony SmartWatch, for example, which we managed to
program by simply creating new definition files and library files for
the Arduino IDE (Cuartielles & Taylor 2013a)⁠—simple for us as expert
users, of course, but not so simple if one lacks the detailed knowledge
of the toolbox, which takes years to acquire. There are SDKs for all
sorts of products, from programmable lamps to robotic arms. Since the
idea behind an SDK is to help developers at companies willing to resell
certain products in specific configurations to create their own programs
to run the devices, the SDK is really a toolbox with a diversity of
software, examples, and sometimes even add-ons complementing it. It is
also open-ended, to be used for different purposes and in different
situations.

Returning to Elliot’s remark that ‘if you want this done tonight, I need
hardware’ *(Mr. Robo*t 2016), it should be noted that the series is
famous for depicting very accurately the kind of tools used by the main
character to hack into a wide variety of systems and obtain information.
It is not the tools, the generic computer gear and office materials, but
his expert knowledge in the field that allows him to make the tools
perform operations that viewers might never have dreamt up. In just a
few minutes he is able to make the best out of the tools to hand. It is
so simple and at the same time so hard.

### <span id="anchor-4"></span>Kits

A kit is a set of tools and materials ready to be integrated into a
preconceived design or specific context. Some kits are made of
disposable parts and once used cannot never be reused, while others are
intended to be reused in different combinations. A kit typically comes
with an instruction manual that guides the user into achieving a certain
end. The ultimate purpose of a kit depends on the context of its use.
There are educational kits that are a series of experiments, while
others are like flat-pack furniture, designed to give users the
experience of assembling their own artefacts and the satisfaction of an
almost-guaranteed success. In fact, not only analogous: one of the
better examples of a kit is the flat-pack furniture box. Its small
screwdrivers and screws as well as the tools included in the package are
designed to last for just that one occasion. The whole flat-pack
furniture industry is built on the idea that apart from the kit,
everyone also has a standard toolbox with a hammer, a screwdriver, and
the like. Such basic toolboxes will still need to be complemented in
order to mount a shelf, put the legs on a sofa, or install a new
kitchen.

Kits have a certain intentionality, as when dealing with preconceived
designs. It is not that the recipients cannot change the kit’s fate, but
success cannot be guaranteed unless it is in the prescribed manner. Its
parts and disposable materials make up an orchestrated series of
sequential steps to provide the user with a somehow expected result.
Thinking in terms of the sociology of innovation, as the sociologist and
engineer Madeleine Akrich puts it (1992), designers, when creating kits,
will force users to fall into categories or ‘user types’. They also
provide a vision—a clear idea of how the kit will enable a
transformation. Those involved in bringing this vision to users are the
innovators who will inscribe ‘this vision of the world in the technical
content of the new object’ (Akrich 1992, 208). Akrich, who I cited
earlier without discussing the intentionally educational possibilities
of kits, therefore calls the final product of such process a ‘script’ or
‘scenario’: the kit is a script to guide our agency towards the vision.

When designing, I specifically avoid defining solutions using methods
such as the use of personas or scenarios. This is what Latour (2006) and
even Stringer (2014) refer to as ‘design for representatives’, since
representatives never represent all of us. Designing kits with personas
in mind is a form of control on several levels. First the experience is
controlled, since the kit gives you the parts and tools to do one
design. There are typically not two plans to build different things, but
one, whether flat-pack shelves, electronics circuits, or a science
experiment for children. A second aspect to this control is the
pervasive dependence embedded in the kits by the manufacturer in the
form of replacement parts, extensions, and complements. Finally, there
is the control element of the software that runs on computational
elements. For example, imagine a content management system (CMS) for a
user to implement a blog.^[^15^](#fn15){#fnref15 .footnoteRef}^ She will
typically install the software from a back-office service, alter its
look and feel using standard software, and upload the blog to a server.
The instructions for building the website together with the actual
software are a kit that will end up in a CMS that will most likely not
satisfy 100 per cent of user needs, highlighting yet another element of
control: software dependency.

The solar energy lamp discussed by Akrich (1992) was an example of a kit
developed for remote places. Part of a top-down experiment to provide
third-world users with lighting, the excessive concretion of the solar
electricity kit made it impossible for it to succeed on this point, and
it also failed to facilitate co-learning and community-building through
its use (experts giving support to less experienced users). In other
words, a failure in the design of these very specific sets of parts can
still have consequences beyond the defined scope of the kit.

What Akrich describes is the virtuous circle of designing a good kit. A
kit can be very educational or extremely practical, but if badly
designed it is doomed to fail.^[^16^](#fn16){#fnref16 .footnoteRef}^
Good or bad design has to be weighed against the expected outcome of the
end user’s experience. The kit has to offer a replicable experience, in
the sense that users know what to expect, and that is why they fall for
a kit rather than a more open-ended toolbox option. This is yet another
view on the controlling nature of kits. While users need to be in
command of the situation—to know how long it will take them to mount the
shelving system or what the expected result of the educational
electronic circuit will be—the kit configures not only the use but also
the user. For the manufacturer of a kit, the metrics are simple: if a
kit sells, it has succeeded in configuring a unified body of users.
Reusability, understood as redundancy of function or materials, gives
users readier control. There are lessons to be learnt from a kit that
has been adopted by a significant number of users. Would greater
redundancy in design, tools, materials, and documentation, which have a
proven record based on metrics, serve to increase the probability of
making new successful designs?

### <span id="anchor-5"></span>Platforms

> The analyst is forced at all times to define the universe of discourse
> within which ‘redundancy’ or ‘meaning’ is supposed to occur. (Bateson
> 1972, 422)⁠

While the toolbox requires a certain level of expertise to get the most
out of it and the kit comes with the intention of empowering users and
educating them, the purpose of the platform is to help the novice become
an expert by participation in a community of co-learning. The platform
is an assemblage in which humans and non-humans co-exist, building and
controlling access to a shared dynamic knowledge base, where
communication is mediated by tools, and actions are performed through
kits and toolboxes (as well as generic materials). A platform is
flexible by nature, especially during its formation and definition. The
flexibility refers, once more, to Gillespie’s notion (2010) of the
‘featureless’. It is hard to say whether the platform emerges in
response to a need, or if the need will be generated by the platform. At
the same time, the definition of what the platform will do arises in the
interaction between developers and users, and that is why its meaning is
created in that exchange.

The idea of redundancy introduced by Bateson (1972, 140) is very much
what defines a platform’s chances of success. A platform explained
through datasheets is a lot less appealing than one explained by
examples of use. Datasheets or, in software, library descriptions as in
the Java programming language, totally lack redundancy. They present the
features of a system and list the collection of available methods and
algorithms of a library, but without trying to convey a meaningful
message. In software, there are tools that automatically extract the
documentation from the library as it was written by the programmers.
Even if this type of documentation becomes relevant over time, it is not
the kind of information users feel compelled to read when about to take
their first baby steps in the world of tools and processes. Yet in order
to attract users to an open-ended environment, it is not enough to
provide a rational purposiveness. What is required is rather a
non-controlling narrative that takes into account that people, in order
to experience a sense of self-control, would rather learn as they go.

It is this open-endedness in the nature of the platform, together with a
feeling of territorial property, which creates a community around it.
The community is the mix of the users or actors and the technology that
supports them. The outcome of a community varies from case to case—a
group of people who watch and comment on YouTube videos will be
different from a group who write and review articles about technology.
In both cases, the creators and maintainers of the platform have to
relinquish some of the control mechanisms to the users in order to
transfer the degree of ownership that will retain participants, and
hence make that platform into a shared environment for decision-making,
relevant over time, or Björgvinsson et al.’s ‘Thing’ (2012). Such a
continuum of user technology is an assemblage in Bennett’s terms (2005),
with an agency that goes beyond those that create it (Rouvroy 2013). The
user thus conditions the technology by requesting different services, or
contributing knowledge, time, or other resources. By becoming active
members of the community, contributing to forums, helping newcomers, and
so on, users gain indirect power in the maintenance of the platform. In
a sense they become constitutive, and therefore part of the continuum.

Lane’s reflections (2014) on the origins of the term ‘democracy’ (power
to the common people or to the many) apply in this case too, as the
platform could be defined as a democratic process, being mutually
constitutive. Yet again, this involvement of people in the platform and
vice versa is a self-control mechanism of a complex system. For it to
continue to exist, it has to please and serve its users; it has to be
designed for and by its users; it has to be commanded by its users in
order not to be corrupted; and it has to sustain the becoming-user or
becoming-subject in a relationally sound way, the users being
‘subjected’ by terms of service, state-of-the-art technology,
constitutive affordances, and disturbing bugs.

Platforms allow for democratization in Saldana et al.’s terms (2016),
but also in Alexander’s (1977), or Feenberg’s (2010). Platforms can
gather and give access to data more easily and in a more pervasive way,
making it available to everyone; at the same time, the process of
designing the platform could be open to all actors. This concept of
shared authorship is in line with a platform’s ability to become a
thing—here a (social) contract between parties. Their featurelessness,
together with their reprogrammability, is what gives platforms the
ability to reconfigure or adjust to new situations. Featurelessness also
brings flexibility, understood as openness or a lack of shape, which
leaves the platform open to interpretation. From a co-learning
perspective, platforms allow actors to learn through their interaction
with other parts of the actor–network, whether human or not. Platforms
can integrate other instances of systems such as tools, toolboxes, or
kits; alternatively, those systems can evolve into platforms when a
community forms around them. Since my theme is platforms and their
relationship to other entities in daily life, what matters here is
whether a platform can evolve into an infrastructure, or whether
infrastructures can be transformed into platforms.

### <span id="anchor-6"></span>Infrastructure

For Plantin et al. (2016), infrastructure studies concern the evolution
of shared, widely accessible systems and services of the type offered
and regulated by governments. Björgvinsson et al. (2012) bring their own
definition by holding infrastructures to be intermediary objects,
designed as part of a design process. Drawing on Leigh Star and
Griesemer (1989), they define them as boundary objects that mediate the
communication among users, professional designers, and existing devices.
Such boundary objects constitute infrastructure of sorts, being material
assemblages such as ‘railroad tracks, cables, or the Internet’
(Björgvinsson et al. 2012, 108) that reach beyond the event, extended
temporally and spatially. Platforms and infrastructure can be compared
from the perspective of scale: the latter used to be bigger as they
affected whole countries, while the former, free from local ties, is on
the transnational and even planetary scale. Currently, any of the
platforms of large social networks—Facebook, YouTube, Twitter—has a
larger technical infrastructure than a medium-sized country. Platforms
also have a higher degree of emergence, for they show up at a high speed
given the right sociotechnological conditions. Infrastructure, on the
other hand, requires the involvement of the political class and other
societal entities, and mechanisms have to be put into motion (with, say,
public tenders to find technology suppliers, public studies to support
decision-making, and budgeting to raise the funding needed) that are
characterized by long lead times, measured in years, and sometimes full
political cycles.

<span id="anchor-7"></span>A concept that Björgvinsson et al. (2012)
introduce is the ‘infrastructuring’ or disintermediation of a thing and
its transformation into ‘commons’. My question is whether it is possible
for contemporary platform–things, which typically appear on the smaller
scale, to become public or shared entities. While infrastructuring in
Björgvinsson et al.’s definition seems desirable, being synonymous with
a co-creative ‘thinging’ that tends to boost user satisfaction when
applied to platforms such as Facebook, Google, and Twitter, the speed at
which those systems change is beyond the co-creative legislation of the
thing itself. A slower pace in the way things adjust would only scare
users away. This means that there is an imbalance between the way
society creates legal frameworks and how rapidly the platforms change.
This is why Mantelero (2016) and Feenberg (1991) advocate a model in
which ethics and more inclusive design processes play a greater role in
the design of systems. This would allow large corporations to
self-regulate and anticipate potential issues.

When it comes to the economic model that sustains the most successful
platforms, it goes hand in hand with the pervasively multinational or
transnational nature of networked platforms. Platforms can be legally
established anywhere and make money through the Internet, challenging
international trade laws and the like. Much of what makes them
attractive to users seems to be their mobilizing potential and the
possibility to connect and exchange information with people from all
over the world.

While infrastructuring talks about deformalizing or disintermediating a
thing so as to leave a legacy and bring about positive change in society
(Björgvinsson et al. 2012), Plantin et al. (2016) talk of
‘infrastructuralizing’ as the negative process of corporate-owned
platforms taking over what should be a digital public service—the
obvious example being Google’s near monopoly on searching, or Facebook’s
on social media. According to Plantin et al. (2016, 3), the boundaries
between ‘the two perspectives’, meaning platforms and infrastructure
‘have become increasingly blurry’, and from the perspective of Web2.0 it
is hard to know what is a platform and what is infrastructure. They try
to shed some light to the matter by making the distinction that while we
tend to think that infrastructure is ‘essential to our daily lives’,
platforms ‘are dominated by corporate entities’. One could well ask why
the public sector allows corporate infrastructuralizing to happen.
Hayles (2009) mentions in her discussion of RFID technologies that the
corporate surveillance we are subjected to is no longer
epistemological—‘who knows what about whom’—but rather is ontological,
as digital platforms are increasingly integrated with our worldview,
covering the physical world and adding communication capabilities to
objects which ‘are no longer passive and inert’ (48), making them equal
to us humans.

People use contemporary digital platforms to communicate with one
another, on a global scale and at no expense, which permits a degree of
surveillance that has no precedent (Krueger 2005; Conniry 2016). The
fact that platforms allow the programmability of applications on top of
their data storage (Helmond 2015) ushered in a type of surveillance that
is inherently part of the platform’s nature: the creation of backdoors
on, for example, the encryption systems that secure the communication
between users, or the geolocation information for a given user (Givens
2013). In a 2013 article, Givens introduces the kind of surveillance the
National Security Agency has been exercising in recent
years.^[^17^](#fn17){#fnref17 .footnoteRef}^ Since ‘megaplatforms’—as
Andersson Schwarz (2017, 386) calls such transnational platforms as
Facebook or YouTube—collect information from people beyond national
borders, would not these platforms transform into gigantic state
machines, spying on other nations? In other words, would not
commercially owned platforms, through government interference, become de
facto infrastructure serving the national interest? In practical terms,
surveillance could escape the autoregulatory actions suggested by
Mantelero (2016) or the implication of ethics (Feenberg 1991), as
mentioned earlier. Is not the possibility of platform-based surveillance
something that could be removed from platforms by design? Would a
platform be allowed to exist if there was no way to control
it?^[^18^](#fn18){#fnref18 .footnoteRef}^

Billions of people interact using social networks such as Facebook or
YouTube. The size of a machine-centric network, like the IoT, is at
least one order of magnitude bigger, and thus the risks of
infrastructuralizing platforms take a new significance. At time of
writing, however, the challenges associated with the IoT have more to do
with a need to follow an infrastructuring process of the concept than
with the risks associated with it (such as surveillance). The IoT
paradigm implies the advent of platforms that are perceived more as
infrastructure, using Plantin’s definition of infrastructure as
essential to our everyday lives. Following a certain business logic, the
corporations offering IoT services tend not to provide their users with
interoperability, in the sense of transferability of data and
applications between platforms. As long as the IoT remains a series of
discrete platforms, it will be very hard for users to invest beyond the
idea of participating in a network of microservices. From another
perspective, Brody and Pureswaran (2014) discuss the weaknesses of the
IoT as not-yet infrastructure, and in a paper on ‘Device Democracy’
analyse the reasons why, in their eyes, the IoT cannot succeed given the
current way the Internet works. They suggest the creation of
micro-exchanges to allow a platform to emerge where users could
contribute by sharing use-time on their devices, but also their data
through micropayments. A system such as this, the authors say, is very
unlikely to come about because of the lack of technical standardization
and regulation forcing all megaplatforms to share data on equal terms.
Perhaps imposing a real infrastructuring, to use Björgvinsson et al.’s
terminology, on the IoT’s technical backbone could be a solution—not a
fictitious one, as proposed by Hayles (2009), but a real
institutionalization of the IoT-related Internet to force a
standardization that would in turn allow for cheaper infrastructure,
devices, and services as suggested by Raghavan and Pargman (2017). This
would eventually have the consequence of reverse open platformatization,
facilitating its societal insertion, and minimizing friction for end
users. Once the backbone had been standardized, it should be easy for a
new type of IoT platform to emerge that could support a model like the
one suggested by Brody and Pureswaran (2014). Currently, it seems the
market is neither interested nor capable of initiating such a model.
This is then the challenge, as pointed out by Hayles (2009) or Feenberg
(2010): we have to publicly embrace technology in order to be able to
make it a public good. Which leaves me asking the question raised by
Hayles: ‘Will the current computing paradigm be co-opted as a stalking
horse for predatory capitalism or can we seize the opportunity to use it
for life-enhancing transformations?’ (2009, 66)

### Performance and pace

What, then, of the accuracy and speed at which computers realize
operations? Technically, performance and pace are determined by the
number of transistors per square centimetre contained in a chip. The
number of switching circuits is what defines the capability of one chip
to perform more operations than another. The pace at which computing
power increases is defined by Moore’s Law, formulated by Intel’s
co-founder Gordon Moore (Mack 2011)⁠, which predicts that the computing
power of processors will double on a yearly basis. Moore assumed that
this would continue for ever.

There are two limiting factors to Moore’s law. One is purely physical.
Transistors can only become so small. The other limitation, however, is
user needs. Why should we continue to innovate in a field where we have
all the computational power we will ever need to serve society? At some
point we will decide we have an optimized processor and, as a tool, its
design ought to be commoditized—in other words, it should be in the
public domain for any community or company to use in optimizing its
(re)production process to make it as good or as resource efficient as
possible. This would be the ultimate democratization of technology,
since actors would just compete on value, as functions would already be
sufficient. An example close to hand is the Arduino board, where—since
its design is open source—we have witnessed scores of companies
competing to make cheaper boards.

Pace, meanwhile, refers to the speed at which new devices arrive on the
market or become more widely accessible. Taking the development of the
Arduino ecosystem as an example, when it first evolved in 2005 there
were few if any competing platforms, and definitely none that included
everything covered by Arduino at the time (Löwgren & Reimer 2013, ch.
6)⁠. At time of writing, the number of similar platforms showing up on a
monthly basis is overwhelming. Once people have registered the
usefulness of a system, whether as a tool or a platform, the pace of
development will increase, as long as there is a way for different
sources to access the blueprints of such system.

The relation between sociomaterial assemblage and its computational
performance points to a whole series of potential lines of analysis,
especially as regards human–human assemblages.^[^19^](#fn19){#fnref19
.footnoteRef}^ One example is the translation of the Arduino IDE. When I
started to work with education as a topic, it became clear that we would
need to translate the GUI of our software to multiple languages. At some
point, there was a contribution from a Japanese Arduino distributor
(SwitchScience) that would permit the translation of the IDE by simply
adding a standard plain text translation file. These files contain a
list of strings in one language and their translations into another
language—English to Spanish, for example. A program has typically one of
these translation files per language. In this way, at the time of
rendering the GUI, the IDE will check which strings are to be used and
which translation in the IDE’s localized language, in order to send them
to the GUI. For this task, thanks to the use of Arduino’s official
software repository (currently a GitHub account), it was possible to
translate the IDE into 40 languages in less than a week. All it took was
that initial procedural work, followed by hundreds of people translating
the Arduino IDE. This is an example of the performative power of a
human–human assemblage, materialized in a bottom-up mobilization in
which participants in a community join forces to tackle a challenge. In
this case it was motivated by a need (having software that operated in
one’s native language) and not by competitiveness (making Arduino’s
software better than other companies’ or projects’ offerings).

Yet pace goes beyond computation and development. It is also related to
the capability of systems to produce data. Hayles (2009), following
Gershenfeld, presents an interesting definition of IoT systems as the
interrelation of readers with tags (RFID) which communicate with
relational databases, combined so they ‘constitute a flexible, robust,
and pervasive “Internet of Things” that senses the environment, creates
a context for that information, communicates internally among
components, draws inferences from the data, and comes to conclusions
that, in scope if not complexity, far exceed what an unaided human could
achieve’ (49).

In looking at how two computational terms—performance and pace—apply to
platforms, it is apparent that computing speed (performance) might not
necessarily be a significant factor for individuals, as their user
interfaces might be good enough to support their interactions with a
platform, but the same cannot be said of pace, or the frequency with
which new systems are developed and presented to the general public, and
how frequently data can be captured from the world given a certain
system. The combined performance of systems with the pace at which data
is produced on platforms, including many of the IoT platforms, creates
new paradigms for how to deal with information at both a technical and a
conceptual level. In such cases it is correct to talk about big data, of
which Hayles claims that ‘the amount of information accessible … is so
huge that it may overwhelm all existing data sources and become …
essentially infinite’ (2009, 47). In a way, the high pace of data
generation will also require higher performance at computing centres
dedicated to the analysis of the data itself. Platform, performance, and
pace must go hand by hand if they are to meet user needs.

Summary
-------

This chapter contextualizes contemporary thinking in the field of
platform design. The first section explores the axes or dimensions of
the discourse, including aspects of the sociology of technology,
engineering, design, cybernetics, and critical theory. In tracing these
axes, I noted clusters of concepts relevant to my theme: the materiality
of actor–networks (sensors, communicators, actuators, modularity,
affordances, embodiments, algorithms), the mechanisms of governance
(distribution, democratization, accessibility, infrastructuring,
ethics), the plasticity or evolution over time (always-on,
featurelessness, neutrality, reprogrammability), and the design process
(disintermediation, generalizability, standardization, punctualization).

In the second section on preconceptions I have concentrated on
actor–networks from the perspective of size (understood as outreach),
performance (their ability to compute operations), and pace (the
frequency with which events and information are generated). I have
explored different realizations of systems as tools, taking a new line
on tools (including state-of-the-art digital technology), toolboxes
(collections of tools and materials), kits (a means of educating and
empowering users), platforms (assemblages co-designed and governed by
users and developers), and infrastructure (the publicly supported
instance of a platform), while noting the issues involved in
transforming platforms into infrastructure and vice versa.

I will next introduce the papers included in the compilation and the
projects that originated them to later filter them through the
above-mentioned framework in an attempt to prove the framework’s
validity.

<div class="footnotes">

------------------------------------------------------------------------

1.  <div id="fn1">

    </div>

    This way of understanding affordance extends this physical property
    to screen-based artefacts. In Fry & Reas 2007 it is briefly
    mentioned in Golan Levin’s additions: ‘Some of the most popular
    machine vision toolkits take the form of plug-ins … Such plug-ins
    simplify the developer’s problem of connecting the results of the
    vision-based analysis to the audio, visual, and textual affordances
    generally provided by such authoring systems’ (554).[↩](#fnref1)

2.  <div id="fn2">

    </div>

    Sun & Barnett 1994 suggested that other networks, such as computer
    networks—the Internet—or the satellite network, should be
    investigated to gain a better understanding of how their development
    was influencing the spread of democracy.[↩](#fnref2)

3.  <div id="fn3">

    </div>

    It is even possible to find an early reference to such an
    understanding of society in the physicist Steve J. Heims’s
    introduction to Wiener’s fifties classic, *The Human Use of Human
    Being*⁠: ‘the long-standing mind–brain duality was overcome by a
    materialism which encompassed organization, messages and information
    in addition to stuff and matter’ Wiener (1989 \[1950\],
    xx).[↩](#fnref3)

4.  <div id="fn4">

    </div>

    Note the difference between Hayles’ ‘thing’ and Björgvinsson et
    al.’s ‘Thing’. It is not only in the notation, but also in
    the meaning. For Hayles, a ‘thing’ is a smart device with some sort
    of distributed computing capabilities. For Björgvinsson et al., a
    ‘Thing’ could be anything accounting for the result of a co-design
    process.[↩](#fnref4)

5.  <div id="fn5">

    </div>

    Note that in contemporary engineering literature we talk of virtual
    sensors, so these do not necessarily represent one-to-one a physical
    sensor in virtual infrastructure, but more groupings of physical
    sensors representing virtual properties. For example, presence can
    be estimated by measuring the number of times a door is opened,
    added to the image from a camera and infrared light reflected into a
    passive IR sensor (a movement detector). Since the virtual sensor is
    always-on infrastructure, it does not matter whether there is a real
    sensor; it can always compute its data from pre-existing records, or
    even infer the information from other sensors on the
    periphery.[↩](#fnref5)

6.  <div id="fn6">

    </div>

    Virt-EU (https://virt-eu.nexacenter.org/ \[11 Feb. 2017\]) is an
    H2020-funded EU project. During the Virt-EU launch, Alison Powell
    gave a talk on ‘Dilemmas of Connected Experience: A Virtue
    Ethics Response’. Alessandro Mantelero gave a speech titled ‘The
    ethics of the Internet of things—what kind of future do we want to
    live in? The EU General Data Protection Regulation and IoT. Legal
    issues of the risk-based approach.’[↩](#fnref6)

7.  <div id="fn7">

    </div>

    My intention in mentioning this here is not to start a conversation
    about legal frameworks and the like, but to highlight that
    socio-material assemblies are hard to regulate, and that their form
    changes by doing something as simple as jumping from the individual
    to the collective.[↩](#fnref7)

8.  <div id="fn8">

    </div>

    Law 1992: ‘punctualized resources offer a way of drawing quickly on
    the networks of the social without having to deal with endless
    complexity’.[↩](#fnref8)

9.  <div id="fn9">

    </div>

    Once I settled on my thesis outline, my draft title was ‘1, 10, 100,
    1000’, in order to show how much size matters to the mindset of what
    one is going to design for.[↩](#fnref9)

10. <div id="fn10">

    </div>

    https://en.oxforddictionaries.com/definition/tool \[11 Feb.
    2017\].[↩](#fnref10)

11. <div id="fn11">

    </div>

    I am referring to the idea of ‘security through obscurity’, which is
    used in the computer security community to express that the best way
    to keep a system secure is by not publishing how it
    works.[↩](#fnref11)

12. <div id="fn12">

    </div>

    At time of writing, I am also involved in the EU project ‘DECODE’,
    for which I am designing a multipurpose single board computer to be
    used in various single-use scenarios. To start with, I have studied
    the performance capabilities of six of the most used single board
    computers in 2017 and the first half of 2018. The study, with over
    750 pages of graphs and 30 pages of analysis, indicates that single
    board computers are very powerful in terms of computational power,
    and that they can be embedded in almost anything.[↩](#fnref12)

13. <div id="fn13">

    </div>

    A microprocessor, also known as a micro processing unit (MPU),
    consists of a central processing unit (CPU) and enough peripherals
    to make it work in a generic way: cache memory, input/output
    registers, clock, etc. A microcontroller contains a microprocessor
    plus program memory (typically flash), read only memory (ROM), and
    some specialized peripherals such as an analogue to digital
    converter (ADC), pulse width modulation (PWM), and so on. While it
    is getting harder to differentiate between microprocessors and
    microcontrollers, the main distinction is in their usage scenarios.
    Microprocessors have traditionally been used in multipurpose
    machines, while microcontrollers were used in single purpose
    machines.[↩](#fnref13)

14. <div id="fn14">

    </div>

    PGP software is encryption technology that allows for secure
    point-to-point communication.[↩](#fnref14)

15. <div id="fn15">

    </div>

    Examples of content management systems are the software behind the
    blogging platform WordPress or MediaWiki (the software package used
    to create Wikipedia). To some extent social networks such as Twitter
    or Facebook can be considered CMS systems, as users can post,
    modify, and delete content.[↩](#fnref15)

16. <div id="fn16">

    </div>

    It is not my aim here to discuss how to design a better kit, but
    rather to give a basic understanding of the various
    definitions.[↩](#fnref16)

17. <div id="fn17">

    </div>

    While the central aspect of the article by Austen D. Givens (2013)
    is how new laws should not be created under emotional stress (like
    the ones that permitted the surveillance of platforms in the US
    enacted in the aftermath of the 9/11 terrorist acts), the article
    stresses that if technology allows surveillance, governments—or
    other entities—will use it as a way of gathering data.[↩](#fnref17)

18. <div id="fn18">

    </div>

    Events in 2018 overtook this thesis, when it was discovered that the
    data of over 50 million Facebook users had been used by the company
    Cambridge Analytica as a way to influence the US presidential
    election in 2016, among others. In an interview in *Wired* in March
    2018 (Thompson 2018), Mark Zuckerberg, CEO and founder of Facebook,
    announced his belief that companies should self-regulate when it
    came to privacy-related issues, but just a month later, during a
    deposition before the US congress (Associated Press 2018),
    Zuckerberg suggested governmental regulation of companies dealing
    with user data. [↩](#fnref18)

19. <div id="fn19">

    </div>

    Muntadas is an excellent human-only example. The catalogue of 2002
    exhibition ‘On Translation’ at Barcelona’s contemporary art museum
    MACBA by the artist Antoni Muntadas includes short texts by various
    authors reflecting on the different pieces exhibited. Caterina
    Borelli (Muntadas et al. 2002, 252) wrote a short commentary on one
    of the artworks that was displayed in the show: a CNN interview with
    Pablo Poliaschenko, a Russian to English interpreter during the
    Cold War. Poliaschenko interpreted for the USSR’s president
    Gorbachev in his conversations with the US president Ronald Reagan
    that brought nuclear arms control to both countries at the end of
    the 1980s. In order to speed up the conversations, they decided to
    change the communication method from interpretation (when the
    interpreter listens to the whole sentence before interpreting it) to
    simultaneous interpretation (done in real time). This demands far
    more of the interpreter, who has to anticipate some of what will be
    said and incorporate all sort of references that go ‘far beyond the
    purely linguistic.’ The interpreter–president assemblage requires a
    certain degree of performance in order to be operative. As Borelli
    mentions in her analysis of the tapes of the interview, the
    possibility of the interpretation being objective is small, which
    means there is a double interpretation: first the interpreter and
    then the president. Such a situation gives a tremendous power to the
    interpreter, as can be understood by watching the interview.
    Reaching an optimal level of performance, both individually and as
    part of a group, is thus key in this kind of human–human
    assemblage.[↩](#fnref19)

</div>
