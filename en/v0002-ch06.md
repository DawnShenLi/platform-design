6 Conclusions and reflections
=============================

> The challenge RFID presents is how to use it to re-think human
> subjectivity in constructive and life-enhancing ways without
> capitulating to its coercive and exploitive aspects. ** (Hayles 2009,
> 48)

Hayles’s point is clear: technology is a fundamental aspect of our
lives, and to resist it will achieve nothing as that will merely
eliminate the good as well as the bad. My concluding chapter will not
attempt to solve this dichotomy; in fact, I hope I will leave readers
with even more questions in forming their own understanding of what
constitutes a platform and how it might be co-created as part of a
democratic process.

This chapter looks at the research questions of whether modularity
constitutes a basic feature for a ‘platform–thing’ and which is a
possible set of functional requirements to create platforms. The text
revisits the work done in order to answer both questions. However, this
thesis is not written as a closed loop, but as steps on a ladder towards
a new set of definitions to be used in real-life cases. The same steps
lead to a more metaphysical discussion about actor–networks, where new
types of actor are already becoming relevant almost as I write.
Contemporary scholars are looking very carefully at artificial
intelligence (AI), a not-so-new actor that is going to produce an
imbalance in the network until we find a new equilibrium, which will
require reconsideration of our own values and even of our definition of
life itself. AI is one of the chief technical factors in the new
platforms, as it helps make sense of the vast amounts of data they
generate. The reflections in this chapter are intended to prompt the
kind of open questions familiar from the international literature, and
which I will continue to research in future.

Designing platforms is about building places for communities to share,
co-learn, and continue to grow (where growth is an interpersonal
emotional quality and not the size of the group). Their construction is
collaborative in nature, and while it can emerge without the
intervention of external actors, design input might be necessary to
spark the process. This thesis specifically explores large-scale
scenarios, where inclusive multiple prototypes were created, deployed,
and tested with a variety of users. Some of the projects have achieved a
certain degree of sustainability, some have evolved and be reused thanks
to their transferability, and others simply vanished after a while. I
have studied them over a long period of time, in response to a general
understanding of digital systems that was only concerned with size,
performance, and pace. As the projects evolved over time, and thanks to
a methodological framework that allowed for the research aims to be
written on the go (research through design), I identified a series of
terms—which I term functional requirements—to be used in addition to my
initial preconceptions as a way to better plan the necessary
interventions to create platforms. This represents a shift from a
techno-deterministic approach to a more community-centric one. It should
be mentioned that I see communities as assemblages of people in an
actor–network, but I do not discount the possibility of according agency
to non-humans, to the point that they could play an active part of
community conversations, the extent of which is discussed below.

This thesis focuses on the creation of platforms as idealized boundary
objects that make actors in a network interact in optimal ways.
Platforms have been seen as initially featureless; this lack of
attributes is a strength, as it allows for the interactions between
actors to form the platform’s affordances and features. A designer’s
role in this scenario is one of participatory activist researcher,
acting as the catalyst in the conversations among actors—whether human
or not—in the network. As I suggest, designers could practise the
meta-design activity of underdesigning the tools and systems in order to
allow users to participate actively in the reprogramming of the
platform, or even its creation in the first place. Modularity,
understood as the design as reusable blocks; density, defined as the
number of users per resource, but also the signal to noise ratio; and
sharing explained as part of a process of openness: all these are key
aspects of platform-building.

My research question takes modularity to be central to the creation of
platforms. Along the way I have discovered that not only is modularity
relevant, but so are the other aspects just mentioned. Furthermore,
there is a dual aspect to modularity, as it has both transferability and
generalizability. Transferability refers to what Björgvinsson et al.
(2012) term ‘Things’, or design outcomes that are created to be optimal
in their reusability. Modularity addresses this from a broadly
structural perspective. Blocks of code can be reused, protocols with
clearly defined interfaces can be reused, APIs with identical method
collections can be substituted for one another, and there are examples
in the technical area that clearly demonstrate the extent. The technical
literature addressed in the thesis points in this direction too, as when
talking about constructing technical networks from standard devices, or
the design of operating systems. The practical cases show also
modularity to be very strong: Arduino is a modular electronics platform;
the SandS modules mutated into the PELARS ones; the haptic modules were
created to be mixed in different configurations made of a single design
block. Generalizability, which is set on standardization, is present in
the functional requirements analysed in Chapter 5. As examples,
obsolescence is possible because there is a standard way to communicate
on the government-regulated radio frequency spectrum (as in the case of
GSM networks), and openness about the processes is a way to ensure an
agreed standardization among parties competing in a certain sector.
Modularity seen in terms of generalizability implies that we should be
creating modules that will be standard for different platforms. Existing
examples of this the authentication methods for digital platforms,
payment systems for online shopping, and UI metaphors for content
management systems. Given the contextualization of many of the terms
used in this thesis, it is now time to revisit my research question,
although first I will introduce my own definition of ‘platform’, for,
following Björvinsson et al. I will not talk of platforms, but of
platform–things.

The platform–thing
------------------

Platform–thing is to platform what ‘Thing’ is to thing in Björvinsson et
al.’s definition (2012). It is a boundary object that augments the
communication between actors in a network, sustaining participatory
decision-making by different means. As a thing, the platform should be
created with transferability in mind, understood in analogy with the
infrastructuring process. The platform–thing makes possible transferable
processes of co-creation, including technological implementation. This
concept, transferability, is easily understood in the creation of
digital platforms, where there are methods—such as open licensing—that
allow for the creation of transferable blocks of code or content. This
can also be ported back to the physical world, as we have seen with the
arrival of open licences for hardware in recent years. All of this
allows for the creation of transversal platform–things that engage both
humans and non-humans, as well as the physical and non-physical realms.

Since platforms are accountable for a series of values (or in my
definition, functional requirements), so are platform–things. Values as
such are soft properties that change over time. Platform–things should
be able to accommodate different sets of functional requirements or
variations of the proposed ones, as they are expected to change over
time. Such variability, especially during the formation of the
platform–thing, should not be a central issue, since platform–things
inherit in an almost programmatic manner the properties of platforms,
such as featurelessness.^[^1^](#fn1){#fnref1 .footnoteRef}^ This lack of
initial definition is counteracted by a social intention.
Platform–things have an embedded social API that sets them up for
possible participation in shared governance, or for enrolling in the
building of the platform, or creating applications on top.

### My research questions revisited

In Chapter 2, I asked whether the basic property of modularity exposed
by Hayles (2009) for RFID could be generalized and transferred to
actor–networks to be used to build platforms, now platform–things. I
approached this concept with a view to reprogramming the actor–network
by creating a new set of rules to get the various modules to interact in
such a way as the result would be greater than the sum of its parts.
This is what should constitute a platform. My first research question is
thus whether this modularity, which we might refer to as transferability
(in the sense that its affordances could be transferred to other
designs) and generalizability (its properties could become a standard),
constitutes a basic feature for a ‘platform–thing’—a sociotechnological
construct for the running of reconfigurable applications—yet at the same
time a sociomaterial artefact for collaborative learning?

Given my definition of platform–thing as a transferable outcome for a
design activity in the more specific context of digital platforms,
modularity is thus a basic property, because it is in the nature of code
to be modular. It then falls to the designers and developers to
underdesign the libraries and basic foundations of the platform—its
blocks of code—to keep them sufficiently modular to be transferable. In
contemporary software design practice we talk about libraries, APIs,
snippets, all of which signify different forms of the transferability of
code and data between developers, but also between entities.

On the other hand, generalizability often depends on whether a platform
is widely adopted, something that is related to its sustainability,
where the size of the community ensures it has the necessary financial
resources to keep the system running. It can also depend on the ability
of platform designers to negotiate with other emerging platforms to join
forces in creating a single way to do that one action. An example taken
from the technical world is the creation of a special interest group
(SIG) to study a communication protocol and manage the IP related to its
implementation. Generalizability can thus be achieved either through
direct growth or through the general growth of the network that the
platform is part of.

Thus I can answer my main research question in the affirmative:
platforms, and more specifically platform-things, have the key
characteristics of reusability and reprogramming, which makes them
modular by design, and also transferable and generalizable.

Regarding the second research question, ‘Given the definition of a
“Thing” by Björgvinsson et al. (2012)⁠ as a “socio-material
assembly”—and my own definition of platform–thing—which kind of
functional requirements can lead the design work towards the creation of
a platform?’ I have responded to the question by looking at a new set of
terms (sustainability, obsolescence, openness, ecology, and community),
which are now part of the new designer’s toolbox for the co-creation of
platform–things.

Visions of possible futures
---------------------------

While strong AI is still far from realized (Boden 2017), which would
imply the artificial reproduction of a consciousness with human
qualities, the notion of an assemblage’s collective intelligence is
still evident in the concepts framed by Bennett (2005), Rouvroy (2013),
Bratton (2015), and even Latour (2006), as if there was a superior
meta-being capable of controlling the direction of the platform’s centre
of gravity, despite the efforts of any of the actors to move in a
different direction. This vision suggests that we should look at
platforms as living entities: as always changing co-learning spaces,
sociotechnical actor–networks with agency as a whole but also as parts,
systems that are somehow self-managed through the interaction of all of
the actors with one another. Thus, we can then also start to look at how
the roles in a platform could be understood in entirely new ways,
challenging traditional conceptions of control (Wiener 1989 \[1950\]),
ownership (Lessig 2001, 318), and even the very nature of life (Conde
Pueyo 2014, ch. 1). The evolution of systems towards this reality
implies that each one of the actors involved is in constant
transformation. In what follows I will highlight some of those
transformations and how they might affect the future of platforms.

### People as sensors

One of the most visible aspects of this transformation of the roles of
actors involved in a platform is how people are no longer mere
beneficiaries of the output of systems, but are increasingly involved in
the generation of data for the platforms, a movement that started with
the transformation of media consumers into media creators (Baigorri et
al. 2005, 165), and that has now evolved with the shift in importance
from content to meta-data (Rouvroy 2013). As long as we talk about the
creation of anthropocentric design, platforms will be there to serve
human needs—which have to be expressed in machine terms and given to the
platform for processing. This automatically makes humans into sensors
(Afolabi et al. 2017), the extensions of the machine who capture
information from the world and give it to their non-human partners for
them to process.

There are sets of transducers that humans use to capture information
from the world. Personal communication devices are now pervasive, and by
the inclusion of sensor technology and the process of capturing all
kinds of contextual information, they have made us humans into virtual
sensors, or extensions of the non-human entity we call a machine (Resch
2013). We have transformed our own role from one of mere users or
consumers of results from the processing operations, to producers of the
information needed to feed those operations. The platform acts as an
intermediary between us and ourselves, while at the same time it depends
on us to feed it, for its own survival. And while the technical platform
lacks the strong AI to reach a certain consciousness and self-awareness
(Boden 2017), the assemblage does have hundreds of humans helping to
build the collective consciousness of the platform.

While we have the choice not to subscribe to the idea of acting as a
sensor, we already do it for the sake of society. Most of us will agree
to give data to medical research, or publish images of our lives online,
or approve of the automated detection of speeding vehicles on public
roads; images and data that are then scrutinized by an algorithm to
extract patterns that will help the evolution of automatic delegation
machines (Adam 2005). To my mind, the challenge is not whether we will
accept this new role of humans in an assemblage, but whether we will be
able to negotiate acceptable conditions for most of us. This is a
complex issue that transcends the purely cognitive aspect described
here, as it affects our ability to decide, the social reality of class
(those with the power to affect and those who do not), the creation of
new types of labour and labour laws, and so on.

### The currency of belonging

There are two aspects to the currency of belonging: the purely
financial, and how much are we willing to surrender our privacy for the
platform (Leckner 2018). From a financial perspective, things cost
money: bandwidth, servers, the workforce to keep the technical aspects
of the platform running, and the like. From this point of view,
belonging to a platform will mean someone will have to pay the bills. If
the user will not, who will? And this the other aspect, if users are not
paying money, could they be paying in another manner? Would those
payment conditions be acceptable?

Currently, platforms are analogous to banks, being intermediaries
between the material and the immaterial realms. Humans represent savers,
but also borrowers’ intent on consumption. Money being saved is the
data, while money being lent is the information. The nature of money
changes the moment it has a purpose; intentions are the meta-data of
money, what contextualizes it. Meta-data is what makes the data
information: the location where a picture was taken, the browser that
accessed a website, the gender of the person who completed a purchase.
For the platform, the meta-data is almost more important than the data
itself, since it helps build relations between users, thus defining
patterns and assigning value (Rouvroy 2013; Brody & Pureswaran 2014;
Mantelero 2016). Contemporary platforms earn money from the aggregation
of the immaterial and use it to pay for the material. They put their
trust in us users to build up enough information through our interaction
with their systems for them to have something to sell afterwards. The
value is not so much in the unique value of a few scraps of information
about us, but in the interaction of that unique value with the rest from
other individuals (Mantelero 2016). Our real individual value is very
low (Brody & Pureswaran 2014). More than ingots of gold, our information
represents the copper coins in the bank cashier’s drawer.

But value is not bidirectional, as the potential pay for what we give
away for belonging is really low. We can get very little for our
information, at least for as long as people keep on trying to produce as
much data as possible, posting their lives on platforms, sending
transactions to databases, geolocating their every movement. Even if
some of the data strikes us as nonsensical or disconnected, the platform
will potentially make sense of it (Simon 1996, 8). On the other hand,
the time we have to invest to become untraceable (while not sacrificing
the use of digital technology) or to erase our traces, represents quite
a lot of work that translates into a real expense for us. Platforms are
not free, and sharing in their benefits comes at a price. The economy of
platforms, especially when they are large, is based on hope and huge
capital investments. These investments come from financial funds that
look for a return on their investment. Sometimes they accept data as
part of the transaction—when it comes to data we are just the coins in
someone’s pocket, and this will become increasingly apparent as time
passes (Arrieta Ibarra et al. 2018).

### Software

The importance of software in the process of building platforms is
crucial. The mere choice of a programming language determines the
capabilities and even the affordances of the user interface. The success
of a platform depends in part on its design, something not covered in
the ‘Lessons learnt’ section of the thesis, as it is not an aspect to be
taken into account on a conceptual level, but rather on a cognitive
level. It is not a given, but it is strongly dependent on aesthetic
values and technical performance at a certain point of time. I touched
upon the idea of software when dealing with terms such as obsolescence
and marketability. Contemporary digital platforms rely heavily on AI,
and need new software paradigms, larger technical infrastructures,
databases of unimaginable size, and data transfers larger than life. The
software needed to command such technical infrastructure, search data,
or trace relation graphs between relevant categories is very complex.
Since data is not always available in the same way and the machine is
not concerned with events (Rouvroy 2013), the answers to my questions
may not be deterministic. Software has to act as an interface to help us
separate the relevant from the irrelevant, so its design is crucial, and
fields such as data visualization are already of uttermost importance in
every scientific field.

The software for any new platform thus has to satisfy the needs of many:
the simple user interface for the end consumer/human sensor; access to
constantly flowing data streams in the search of information (events);
the analysis of patterns and decision-making by AI engines; the
visualization of information for those controlling the validity of the
algorithms; the ease of development and the cost of the tools for those
creating the platforms. Future software for platform-making is one of
the biggest design challenges we are currently facing. Large
corporations are already offering institutions and individuals the
chance to build using their proprietary software tools on top of their
own big data infrastructures, but that is still far from optimal. There
are already indications that software will be one of the most active
fields of work for interaction designers in the near future.

### Protocols

Protocols describe the communication process between the different
actors in the assemblage: humans with humans, non-humans with
non-humans, but also between humans and non-humans. Protocols even help
establish intra-platform communication mechanisms. Protocols give the
reference for how communication will be established, which patterns of
information have to be exchanged for a valid exchange to take place, and
the formats for encapsulating data. By establishing standardized ways to
exchange data, we are also opening for the possibility of letting
platforms grow, since they could, say, syndicate knowledge bases in
order to improve their ability to realize certain tasks. Standardized
communication mechanisms could also help create ways to audit a
platform’s ethical aspects. I can imagine the creation of ethics APIs,
used to exchange information with regulatory bodies in an automated
fashion to make sure operations follow the law. The more we can delegate
these platform actions, the more we can focus in improving other
qualities, or in actively participating in the co-learning of new
aspects that might be relevant to platforms.

### State machines

Among the non-humans participating in platforms, in the future we are
going to find more and more digitally enhanced artefacts. Technology can
be embedded in everyday devices, adding new kinds of functional
possibilities we have not thought of. But the possibilities of digital
technology are also to provide devices with their own reactive
behaviours to variables from the environment. State machines are control
mechanisms that allow assigning behaviours to simple machines without
having to orchestrate their responses from a central authority at all
times. For example, a lift should be able to move up and down in a
building without having to obtain approval from a central control unit.

Small devices typically do not run an operating system—in other words,
their software is not general purpose in nature, but rather a simple
executable that can be changed by reprogramming. That reprogramming is
done with a communication protocol imprinted in the device when it is
manufactured. For example, an Arduino board protocols is part of the
so-called bootloader, a piece of software whose only function is to
reprogram the device.

Simple human delegations can be translated into state machines that
reproduce a scripted series of commands multiple times. But given that
we humans already act as sensing devices for platforms, could not we be
seen as executing simple scripts especially programmed for us? Have
platform developers worked out how to hack into human consciousness by
implanting state machines in our clothing and getting us to perform
involuntary tasks to feed the platform with data? Leaving aside the
conspiracy theories, could it be possible that the collective
consciousness of the platform has made us into our very own state
machines, designed in such a way as we can morally accept their
existence?

### Algorithmic sovereignty

In contemporary digital society, control is enacted through machines
commanded by dynamic programmatic structures. These structures, which we
call algorithms (Dourish 2016), operate using data that has been
deprived of meaning (Rouvroy 2013), and therefore has become irrelevant
to us whilst it makes us insignificant, as our singularity is diluted in
matrixes of aggregated raw information flows (Mantelero 2016),
automatically categorized by the algorithm itself. Rouvroy presents the
difference between judgement and critique when talking about AI.
Judgement describes the ability to cluster data into categories.
Critique, on the other hand, defines the possibility of challenging the
categories to better accommodate the data. Both actions, up to the
arrival of AI, were done by us humans, but that has changed now. AI is a
system that never stops, where error does not exist, where events are
washed away, and where categories are defined automatically by DL
algorithms according to parameters we can never understand. This makes
impossible for us to challenge the categories, which precludes us
criticizing anything, including the machine itself. In this case,
neutrality excludes not just one type of human, but the human race per
se. This is a new type of neutrality where we are all equal to the
machine, but not equal with the machine—the concept to challenge through
algorithmic sovereignty.

While hardware is complex in nature, to the point that it is not yet
auto-generative, software and the abstraction that it derives from
(meaning algorithms) can be produced by software. The level of
delegation we have in software is unlike almost anything else before in
history in scale and responsibility. However, regulatory efforts will be
put in place at some point, since this is how our socioeconomic system
works (Dutton 2014). Once there is a potential point of conflict,
society builds a new failsafe switch to try to control the situation.
There are historical examples that range from the creation of laws to
stop unjust cases to the evolution of political systems that are more
humane and up-to-date with our understanding of the world. It is only a
matter of time until new standards and regulations start policing our
new AI-centric reality. But if that is going to happen, where then is
the risk?

The production of data is embodied. We are the sensors when we are one
with our pervasive measuring tools: some comes from our daily
interactions with others; some of it is generated by our
self-quantification devices; some of it is a trace left when conducting
financial transactions with the always-traceable, always-ubiquitous
digital money. It is worth asking ourselves if it makes sense to work
for a future where humans work in data farms, feeding self-thinking
machines in a sort of symbiotic relationship. It is hard to understand
how a symbiosis with algorithms could work. It is much easier to imagine
a parasitic relationship, where algorithms extract the value from us by
forcing us to abandon what is relevant to focus on making what they
need. The mechanism we choose in order to keep control is what I like to
call algorithmic sovereignty, or the ability to exercise power through
algorithms, the main abstraction within the human–machine assemblage our
society is becoming.

### Platform design in a time of AI

This thesis starts from the premise that platforms emerge where user
needs meet the developers’ ability to deliver systems accommodating
those needs. Furthermore, I have shown that platforms are boundary
objects between stakeholders in actor–networks. In a sense, platforms
use the networks’ meta-data to create new digital contexts, as
participation in platforms implies closing a behavioural loop between
the system and the user both as an individual and a part of a
collective, from personal and aggregated data alike. Platform–things are
designed to be modular, generalizable and transferable, acting out
scenarios if use that, once abstracted in the form of patterns, can be
reused. AI can make predictions and analyse possible scenarios using
so-called brute force combinatory strategies, weighed against one
another to decide the best possible outcome based on the metrics used to
train the expert system. Could not then a trained AI algorithm create
platform–things based on existing designs or patterns? While my research
thus far has demonstrated the inherent complexities when designing
platforms, given the computational ability to anticipate (and therefore
simulate) the behaviour of systems, how much of the work of the creation
of platform–things could be taken over by algorithmic intelligence? The
real question, having analysed the state of the art of AI technology, is
no longer whether artificial systems will be able to synthesize new
platforms, given an existing set of design patterns to enable the
interaction between humans, for such a possibility seems plausible. The
real question is whether AI will be able to anticipate new modalities of
interaction, and alternative user journeys for communicative purposes,
in what in essence would constitute new artificial designs for
platform–things.

<div class="footnotes">

------------------------------------------------------------------------

1.  <div id="fn1">

    </div>

    In object-oriented programming, we talk of different classes
    (definitions of variables in the system) inheriting properties from
    others.[↩](#fnref1)

</div>
