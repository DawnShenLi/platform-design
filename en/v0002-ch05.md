5 Lessons learnt
================

This chapter is a re-examination of the preconceptions outlined in
Chapter 2 in the light of the experience of developing the projects
described in this thesis. It became evident that there were intentions,
needs, approaches, and mindsets that only transpired as the projects
evolved, and since my original framework, the manifesto detailed in
Chapter 4 (Cuartielles 2004), was never meant to be a hard and fast rule
for how to proceed with the research, more a display of the
possibilities, I simply incorporated new perspectives on how to deal
with some of the as yet unsolved challenges in platform design as they
emerged. The result, presented here, is a revised framework that takes
an experience-based, augmentable, and modular view of platform design.
No longer detained by spatial (size) and temporal (performance and pace)
issues, this framework 2.0 is more holistic in its approach,
incorporating the soft qualities that are central to contemporary design
discourses.

Not only did my thoughts evolve as a result of my practical experience
gained while co-creating systems such as Arduino, the indoor location
system, SandS, PELARS, or the haptic-enabled wearables, but also because
of I have closely followed the literature on interaction design, the
sociology of technology, the arts, education, and engineering. Given
that I have been engaged in this process for a longer period, I have had
the chance to witness how the evolution of technology and its
interaction with us humans has been disseminated in academic
publications, the specialized media (such as engineering magazines), as
well as non-specialized literature. The last fifteen years have seen the
paradigms of ubiquitous and pervasive computing become a reality. The
sociology of technology has returned to actor–network theory with
renewed interest thanks to new studies that apply it to contemporary
technologies such as the cloud, APIs, and AI agents (Bratton 2014,
2015). In the context of education, technology seems a catalyst in the
move towards learning paradigms such as project-based learning or
experiential learning (Säljö 2010). It is now common to see interactive
digital technology as part of artistic performances and integrated into
artworks (Fry & Reas 2007, 501). Engineering is flirting with the new
values generated by AI by addressing the ethical questions raised by
autonomous vehicles moving freely on the streets (Johnson & Miller 2008;
Levinson et al. 2011). Trade is conducted by automated systems (Cox
2017). Even insurance companies are looking at the potential risks and
opportunities of the interactions between actors in the always evolving
network of connected flesh, cogs, and bits (Yeomans 2014).

This double helix of praxis and theory has led my understanding of the
field to drift away from the technology-centrism of my early work
towards one where an assemblage of non-human and human actors share the
spotlight. I have come to understand the ideas suggested by
actor–network theory as a continuously constructed tracing of
interaction patterns, modes of use, and social relations (mediated by
technology). I myself have traced the actor–network of platform design
through an iterative design process, which has brought into play a new
set of assumptions to help mapping the networks in a way that looks
beyond their spatial and temporal attributes. It is analogous to the
microelectronics business—it is a complex endeavour to set up a factory
dedicated to the production of microchips at the highest level of
miniaturization in one take. The creation of such a megastructure (and I
am talking here about the process of building an extremely precise
assemblage, where humans and non-humans work in a never-ending shift and
processes and artefacts have to be synchronized to inform one another in
an unceasing cycle) requires an iterative process of refinement
stretched out over a long period.^[^1^](#fn1){#fnref1 .footnoteRef}^
Reflecting on the relationship between these complex assemblages and
platforms, I reconsidered which tools are needed for the creation of
platforms.

Thus this chapter presents the set of tools that have become part of my
personal design toolbox, and which have been refined through an
iterative design process. I would suggest they make a useful framework
for designing and building platforms, as they bring together a set of
discursive elements to open the conversation when co-creating a system.
All the terms have featured in the thesis thus far—sustainability,
obsolescence, openness, marketability, community, democracy (from
technological empowerment), the political, ecology—and, rather than
being intended as absolute truths, they are open for negotiation, being
tools to help when modelling assemblages and their contexts and when
dealing with new platform design. They are not all needed at once, and
each might or might not be needed at a specific moment in the evolution
of a platform. For simplicity, I present them in a logical sequence of
sorts, but this is not to imply that they should be introduced into the
design process in the same order, nor that they should remain unaltered
throughout. Just as in the example of building a microchip factory,
iterations and a continuous evaluation of the process are needed when
building a platform—it is the price to pay for the platform’s
featurelessness.

In describing the terms I have continued with the chronological
disposition as the most appropriate. Thus I begin by introducing the
discursive tools in the order of the papers in the compilation, while
the in-depth explanation of those terms must wait until the second part
of this chapter, where I enlarge on the discussion by adding a critique
of each of the topics.

Papers and other projects
-------------------------

This first section will look again at the papers in order (see Chapter
3), but also at the projects I have used to illustrate the various cases
considered in this thesis. By looking at how the terms shifted in
relevance over time, the process of understanding how platforms are
formed becomes into focus.

### Paper: Research design applied to platform creation

When I wrote my resign desearch manifesto in 2004, I was unaware that
platforms would become increasingly relevant, and thus instead of
studying the design of platforms, I was more interested in the idea of
how *digital manipulatives* as *digital materials* could become part of
everyday design practices (Resnick et al. 1998; Redström 2001;
Cuartielles 2004). The idea of *democracy* from the perspective of
access to tools and processes (see Chapter 2) has always been my
interest, and it is therefore the first of the terms to feature. In the
manifesto, democracy is related to the concept of design collection as a
way to reach as broad an audience as possible, and thus be more
accessible. Closely related to it one finds the idea of *marketability*:
given that Sweden (like all of Western Europe and a majority of
countries worldwide) is a capitalist economy, and given that technology
is materialized as products people can buy, including the idea that the
design objects had to be attractive to contemporary economic cycles of
offer and demand, marketability came very early to be part of my
discourse. Many of the projects I realized between 2005 and 2012 were
funded either privately or aimed to reach a certain degree of commercial
exploitation. This has ethical implications that I will discuss later
when exploring the political aspects of platforms in greater depth.

### Project: ‘Micromobility and Learning’

The first research project I joined, ‘Micromobility and Learning’,
looked at how education related to learning spaces (described in Chapter
1). From this project I learnt how to describe an assemblage using the
term *ecology.* It was when considering educational experiments that the
conversation turned to the fieldwork methodology used to collect data in
experimental settings. The configuration of a classroom is typically
determined by certain conditions—its location, the number of teachers,
the number of pupils, the duration of the class—which put together
comprise the class’s ecology. When running an experiment about the use
of a specific technology in a classroom, the nature of this ecology is
transformed by the temporary presence of exceptional actors:
researchers, cameras set to record whatever events are thought relevant,
people take notes and ask the participants (pupils and teachers) about
how things feel or work. This gives the class a different setting, a
different *ecology*.

An analysis of the ecology of an experiment matters because of the
question whether the experiment could become the norm after the
researcher’s intervention. It may be a challenge for the teacher to
repeat the same kind of experience without external help. The question
is then whether the experimental ecology design was good enough to make
the whole assemblage sustainable. *Sustainability* here refers to the
resources needed to support a certain situation. Other possible meanings
of sustainability—namely those referring to environmental aspects—did
not become part of my toolbox until later.

### <span id="anchor"></span>Paper: An indoor location system that went nowhere

Research projects can have more than one outcome. The indoor location
system produced as part of the research done with the University of
Zaragoza—and which became sideline in the ‘Mobility and Learning’
project—had an excellent academic outcome.^[^2^](#fn2){#fnref2
.footnoteRef}^ Our work was published in *IEEE Pervasive Computing*
(Casas et al. 2007) as a paper that looked not only at the technology,
but also at the hidden issues behind installing something as complex as
an indoor location system. Among the learnt lessons included in the
paper were a great many interaction design aspects, such as how to
configure a system with the smallest possible number of operations,
which kind of installations could take place, and how such a system
(conceived at the beginning of the IoT era, after all) could be
implemented in spaces that were never designed to host embedded
electronics in their structure.^[^3^](#fn3){#fnref3 .footnoteRef}^

While the technological achievement of the project was remarkable, it
was less clear how to proceed to make it useful beyond its academic
results.^[^4^](#fn4){#fnref4 .footnoteRef}^ When the time came for us to
decide how to ensure the invention continued, there was no agreement on
how to move forward. It being 2003/2004 the concept of open-source
hardware licences was still unfamiliar at the institutional
level.^[^5^](#fn5){#fnref5 .footnoteRef}^ Our only option seemed to be
to patent the technology and try to sell it on, or even to start our own
company to exploit the results. The main problem was that our technology
was a proof of concept, and it was a good ten years ahead of its
time.^[^6^](#fn6){#fnref6 .footnoteRef}^ So while the indoor location
system was very interesting experiment, it was not shelf-ready
technology waiting to be adopted by a start-up company as its main
source of revenue. In the absence of dissemination alternatives,
compounded by differences within the team on how to proceed, the indoor
location system was doomed to disappear as a technology.

One term that arose in discussion during the final phase of this project
was *openness*. In interacting with my partners at the University of
Zaragoza, I learnt that openness was an activism of sorts. Why else
should one create something and share it with others with no apparent
economic benefit attached to it? It would be years before open-source
hardware would be recognized as an accountable outcome for
research.^[^7^](#fn7){#fnref7 .footnoteRef}^ When it comes to business,
open source and open innovation (a more abstract term) have been
reported to produce indirect outcomes for those generating the
technology (Hippel 2005; Cuartielles et al. 2018).

### Project: Arduino

The Arduino project plays a pivotal role in my research. With a
community of hundreds of thousands of users participating on its online
forum and millions of visitors every month (Cuartielles et al. 2018),
Arduino has transformed the way people understand educational technology
by moving from the institutional laboratory to the personal, portable
one. It has democratized access to the exact same tools for people from
all over the world at prices adjusted to their needs (thanks to the
arrival of derivative designs and clones on the market). Arduino
represents many things, and it definitely includes—as a platform—all of
the terms I present as tools in this chapter; however, the most
important is the idea of *community*.

Building Arduino forced me and my partners on this journey to think
beyond the technology. All of the sudden, our work was relevant to
people on the opposite side of the world in ways we could never have
imagined.^[^8^](#fn8){#fnref8 .footnoteRef}^ Arduino is used for
learning about digital technology, building electronic controls for
aseptic rooms, launching small low-orbit satellites, making machines to
explore the bottom of the ocean, controlling liquid mixers in the food
industry, or building braille learning devices for children with visual
impairment. The sheer number of people using Arduino in their daily
lives makes it very successful as a project. Many of them collaborate on
the technology’s further development, assist others in the online forum,
arrange real-life events to talk about it, or write books to share
knowledge about the platform. These people comprise the Arduino
community of users and developers. No other project I have been involved
in measures up to Arduino in terms of community-building.

### Paper: Haptics

The various projects on haptics dealt with the idea of spatial and/or
temporal interactive experiences. The prototypes analysed in the papers
were built to explore the possibility of creating multiple artefacts
that could interact with a person or a collective because of either
spatial or temporal properties. All of the experiments investigated the
concept of inclusive multiple prototypes, introduced earlier (Chapter
4). We jumped from an experiment where scores of actuators attached to
the body were triggered in preprogrammed patterns according to the
location of the user, to one where hundreds of actuators on one suit
were activated by another user touching an identical suit at a remote
location. All the prototypes were extremely time-consuming to build and
needed every hardware and software trick in the book to make them work.

If there was one word that dominated in this project in a way not seen
in the others, I would say it was *obsolescence*. It was centred on the
key limitation while building inclusive multiple prototypes: money. To
build the prototypes, hundreds of circuit boards with processors had to
be made. At the time, we could not afford expensive prototyping services
or parts, and this forced us to be very creative in the way built
everything. We made revived a whole series of obsolete techniques,
including token-ring to implement the communication between the various
parts of the prototypes.^[^9^](#fn9){#fnref9 .footnoteRef}^ But the term
obsolescence has a much deeper meaning, especially *planned
obsolescence*, which can be contrasted to the idea of *enough computing
power* which I presented in the theoretical framework of the thesis
(Chapter 2). I will detail the concept below, along with the
relationship of obsolescence with sustainability.

### Project: ‘Creative technologies in the classroom’

It was not long after we built Arduino to give our students access to
state-of-the-art embedded hardware development tools for interaction
design that the tools themselves were adopted wholesale by other
educators. As well as redeveloping the Arduino tools as a platform, I
joined a group of upper secondary school teachers in experimenting with
the adoption of embedded technology in the standard school curriculum in
science and technology. I conducted workshops on basic
twenty-first-century digital skills and computational thinking for
educators in Spain in 2006 and Argentina in 2007 and 2008; workshops
that resulted in the creation of educational resources by the teachers
themselves, designed to be used in their classes. I was concerned about
transcribing my process so it could be adopted by others, but it was not
until 2012 that I had the opportunity to design a project to address
some of the issues I identified during those early experiments.

The ‘Creative Technologies in the Classroom’ (CTC) project thus
represents my personal take on a formal education in technology at the
upper secondary level. It was intended to become a platform where
teachers could learn about educational technologies while teaching.
*Sustainability* was the key concept, as the intention was to help
teachers become self-sufficient in exploring the use of digital
technologies in their classes. CTC was (and still is at the time of
writing) a project with a political agenda, devised to return power to
teachers so they can decide what is relevant in an ever-changing
context; digital literacy is simply not enough, for so-called
twenty-first-century skills must be constantly refreshed, as digital
technology is a fast-evolving field. The project not only began by
centring on an inclusive multiple prototype—with hundreds of people
involved in the first iteration, jumping to thousands of users for the
second and all subsequent iterations—but it continued to do so, as I
managed to run the process internationally over a period of four years.
Marketability became increasingly relevant for this project, as the NGOs
covering its expenses could sometimes not provide enough materials for
the schools, necessitating that we make CTC kits into products to help
the schools otherwise left without the parts they
needed.^[^10^](#fn10){#fnref10 .footnoteRef}^

The experience of using a kit to achieve something technically
challenging is an empowering one. I have seen it in a range of projects,
resulting from different instalments of CTC. Now in its fourth edition,
CTC is still a kit used to show upper secondary teachers how to
introduce technology to their classes. The project has been run in
Spain, Ecuador, Mexico, and Sweden, and by the end of 2017 had reached
over 17,000 pupils in interaction with more than 1,550 teachers in over
730 schools, using 860 kits. Given the nature of the project, the kit
played a very important role, and its design was iterated year on year
to include feedback from participants. Besides a few bugs in the
software or the occasional problem with the online documentation system,
the response from teachers and pupils was generally very positive.
Thanks to the interaction with the kit and with other teachers in the
project, teachers were able to pursue a project-based learning
methodology that included the use of software and hardware tools, all of
them documented as interacting with one another as part of the kit.

### Paper: SandS and PELARS

The two European research projects I have included in this compilation,
SandS and PELARS, are represented by my design diaries for projects.
Each paper analyses the work of creating an accessible technological
platform to connect the physical world with a digital artefact, and from
there to other artefacts via the Internet. The inclusive, multiple
nature of the two projects comes from their coverage of an entire
vertical segment of their respective fields (IoT for households in the
case of SandS, computer-assisted super-fast prototyping with digital
tools in the case of PELARS). Both projects had a series of prototypes,
user tests, and long development times, and resulted in artefacts
created with a degree of marketability in mind.^[^11^](#fn11){#fnref11
.footnoteRef}^

Besides looking at the possibility of the research results becoming
products and services available to a larger audience, SandS explored the
idea of obsolescence by upcycling existing non-connected home appliances
to a dedicated cloud so that users could use them for new types of task.
PELARS, meanwhile, investigated the democratization of prototyping tools
by creating a more egalitarian system, which, thanks to its ease of use,
would make digital prototyping with physical artefacts possible for
people who have no knowledge of software or
hardware.^[^12^](#fn12){#fnref12 .footnoteRef}^

Overall concepts
----------------

Going back to the series of spatial preconceptions (tool, toolbox, kit,
platform, and infrastructure) I presented in Chapter 2, because they
only concern the size of the system they barely scratch the surface of
platform-building. To recap, a tool is about a person’s interactions
within a context via a machine; a toolbox involves several machines and
materials; a kit introduces in the notion of a predetermined goal, plus
the intention of educating the user; and a platform and infrastructure
take it to the level of public and private. When it comes to the
temporal aspects, performance concerns computational power and
processing speed. An analysis of a system using such terms will be very
techno-deterministic in nature. While they offer a valid view of where
platforms fit in a larger ecosystem of things, I have observed over the
course of the projects discussed in this thesis that an entirely
different terminology is needed specifically for building platforms. A
simple analysis in terms of scale and performance cannot explain the
various aspects my experiments show to be relevant. This section thus
offers a whole new series of functional requirements (to borrow a
technical term from computer science) for designers to approach platform
design with new eyes. The concepts are arranged in a progression from
technocentric to the participants’ co-learning, via collaborative action
in the creation of platforms.

### <span id="anchor-1"></span>Sustainability

Krippendorff (2005), Callon (1991), Latour (1996), and Bennett (2005)
help in describing the idea of an assembly as ecology (which is
discussed below), there are practical frameworks that could serve as
examples of how it has been applied in real life. One documented case is
USAID’s document referring to the 5Rs framework (USAID 2016), which
promotes sustainable projects and activities via local actors and
systems. The 5Rs framework takes its name from its approach: the ecology
of systems should comprise the five R’s of results, roles,
relationships, rules, and resources. While results represent an
intangible, unexpected, and unknown asset (we cannot foresee the
future), the other four terms are simply another way of looking at
actors and intermediaries (Callon 1991), and how they interact in
building networks. Sustainability, which is the term under discussion
here, depends on realizing results that stakeholders truly value, and
the ability of the system to produce valued results over time (USAID
2016)—in other words, it is strongly linked to the idea of duration over
time, which is achieved if the results are satisfactory to the people
involved in the process.^[^13^](#fn13){#fnref13 .footnoteRef}^

Sustainability can be also understood from the point of view of
availability. For example, if a certain technical resource is simplified
in order to make it easier to replicate, more of that resource can
exist, as Raghavan and Hasan (2012) conclude when looking at Internet
infrastructure. They conclude that a system such as the Internet, which
can be implemented so that it is free of single points of failure by
simply replicating pieces of the technical infrastructure, is far more
sustainable thanks to having readily replicable, and thus readily
available, devices, which seems to also be more environmentally
sustainable. Raghavan, teamed up with Barath and Pargman, offers a
closer analysis of this ecological aspect when studying ‘sustainable’
human–computer interaction (Raghavan et al. 2017), and suggset that
intermediation is responsible for more complex and therefore less
sustainable resources, and ‘increasing complexity in itself is
unsustainable’. Their work is not a manifesto for simple or simpler
systems, but for the removal of intermediaries that increase the number
of steps to the outputs of systems, and with it the cost. An example of
this cost increase is the one mentioned earlier when talking about
openness and the patent system in Hippel’s work (2005, 114), where costs
increase as more patents from different sources are applied to the same
product, ultimately making it unsustainable. But Hippel, just like
Papanek (2011), Mari (2017), and Lessig (2004), is more concerned with
how openness in design can make design more sustainable. If someone
figures out a way to improve a certain design which they then publish,
it will be more widely used, easier to manufacture, and by extension
more sustainable. Hence the extended life of GSM technology, the
communication technology that powered the first digital mobile phones,
which is still in use as a fallback solution and for the production of
cheap mobile devices. As the patents behind GSM slowly expire and
therefore become ‘open’ (Goodman & Myers 2007), the added expense of
licensing over and above the technology vanishes, just at the time when
the increased knowledge about how to manufacture better modems using the
GSM protocol makes it less complex to produce communication devices
using that technology.^[^14^](#fn14){#fnref14 .footnoteRef}^ Thus, this
technology is more sustainable, while being more resource hungry—less
environmentally sustainable—than other more modern technologies. As
technology evolves, communication protocols use less bandwidth, less
transmission power, higher compression rates that save power and
transmission spectrums, thus making newer devices less resource-hungry,
and that translates into needing smaller batteries and therefore being
less harmful to the environment. If we look back at the history of radio
communication, the simplest AM radio receiver can be made with a potato
as a power source and a few components. It is hard to get rid of older,
largely deployed technologies for two reasons: users may resist
acquiring new devices to perform the same function as the older ones,
and these technologies are—by definition—more sustainable as they are
technically simpler (this is only temporary, though, for once the new
technology is widely adopted, it is the old one that becomes less
sustainable).

### Marketability

Marketability is a concept directly linked to the economic
sustainability of a platform, and while it might be of vital importance
for its raising and maintenance, not all platforms are necessarily built
on a market paradigm. For platforms there is a strong link between
sustainability and marketability. Marketability determines whether
platforms will last over time, thanks to their ability to generate an
economic flow that means they can survive and grow as part of the
capitalist system they belong to. When building a platform, people
become invested in the process because of very basic interests such as
the need for tools to execute certain actions or social acknowledgement
as documented in the analysis of open-source projects by various studies
(Malinen et al. 2010; Geipel et al. 2014). However, the creation of
large platforms seems to call for mixed models—what Hippel (2005, 91)
calls a ‘private–collective’ model of innovation incentives—in which the
various people agree to have different interests, some of them being
economic in nature, as seen, for example, in the case of Guifi.net in
Spain (Baig et al. 2016) or Arduino (Cuartielles et al. 2018). What
Guifi.net and Arduino indicate is that the long-term sustainability of a
platform is going to depend on the ability of its members to build a
relationship with the existing economic system, which for Western Europe
at time of writing is the market economy. This relationship has to be
satisfactory to all parties—users, developers, and any
intermediaries—and it has to be formalized with an agreement where the
intentions of all actors are clearly described.

At first glance, the evidence seems mixed as to whether it is only in a
situation such as Guifi.net’s or Arduino’s that a hybrid system can be
sustained, in which some of the collaborators are volunteers and others
receive recompense for their participation. There are other platforms,
like the one supporting the creation of the kernel (the core, or the
basic building block) of the Debian operating system, where all of the
work is supposedly done by volunteers (Zacchiroli 2011). In my opinion,
Zacchiroli, in his lecture of 2011 (on the topic of the creation and
maintenance of the Debian OS) stated that the Debian developers were not
paid by Debian, but *not* that they were volunteers. Consider the *Linux
Kernel Development* *Report* from the Linux Foundation (Corbet et al.
2012), which said that 75 per cent of the Debian developers were paid:
‘7,800 individual developers from almost 800 different companies have
contributed to the kernel … in fact, the individual development
community has doubled in the last three years’. Its 2017 report revised
the figures upwards: ‘15,600 individual developers from over 1,400
different companies … The number of companies supporting work on the
kernel appears to be stable and not growing like the number of
developers \[… and\] well over 85 per cent of all kernel development is
demonstrably done by developers who are being paid for their work’
(Corbet & Kroah-Hartman 2017). What this demonstrates is that, in order
to create a sustainable platform, it is important to be on a good
footing in the existing socioeconomic paradigm. In Linux’s case, the
market contributed 85 per cent of its development costs in the form of
corporations paying for the development time by getting some of their
employees to write code that is ‘pushed’ to the common pool of
code.^[^15^](#fn15){#fnref15 .footnoteRef}^ For example, according to
the report, the largest contributor to the Linux kernel in 2017 was
Intel, one of the largest corporations in the world. The true volunteers
Zacchiroli was talking about only account for some 15 per cent of
contributions; however, this has doubtless changed over time, as the
evolution of the reports shows. Going back to 1991, when Linus Torvalds,
creator of Linux, published his work on the invention of the Linux
kernel, 100 per cent of the contributions were made by volunteers, but
as the importance of Debian has grown over time, other actors—including
some with a financial interest—have become contributors. Yet without the
volunteers, the platform would not exist. The conclusion to be drawn
from this is that relationships between human actors and the platform
change over time.

It should be noted that marketability is not opposed to openness, as the
Debian case shows. By making knowledge freely available, it does not
mean that the work needed to produce it should be done at no expense,
nor that the knowledge itself cannot be sold. To quote Stallman, ‘*Free
software* is a matter of liberty, not price’ (2002, 43). Later in the
same essay, Stallman develops this argument by identifying three layers
to the marketability of software: creation (development), use, and
distribution (intermediation).^[^16^](#fn16){#fnref16 .footnoteRef}^
These three define the current business models for the creation of open
knowledge, allowing developers to make a living by creating better
tools, and thus making the system sustainable. For example, in the case
of my own experiments, CTC was an open educational hybrid of service and
product that was developed with funds from private foundations, and is
now sold by the Arduino company, while Arduino boards are open designs
that run on free software, but they are sold on both online and offline
stores all over the world.

This offers an opportunity to discuss the ethical and political
implications of working with a project like Arduino, which evolved from
open-source project to incorporation as a company in several countries.
Being part of a project like this, as both a participatory activist
researcher and co-founder, raises questions regarding the ability of the
researcher to remain true to the participatory aspects of the project.
Marketability implies being part of a market, where people buy and sell
products and services, where decisions are not always made based on the
same values as those of participatory activist research, and where the
researcher is just one part of the governance mechanism and not the one
with the last say. Marketability, as a characteristic of the platform,
can conflict with its other values. This is yet another reason to take
the market into account and be ready to consider how much it could
compromise the projects functional requirements and intentions. In the
case of the Arduino company, to follow up on an example mentioned
previously (and always judging in retrospect), the radical openness of
its development processes could have hampered its decision-making, which
would have impacted on the marketability of the tool and therefore its
sustainability. The question remains whether we could have done things
differently, while still ensuring the sustainability of the project. Was
optimizing marketability the way we did it a good-enough strategy? To
what extent did concerns about marketability compromise the
establishment of the Arduino community? When looking at the current
metrics of the Arduino project in terms of usage and Internet
popularity, compromise might not be the first thing that springs to
mind; however, there is little to be said about things that never
happened, and we can only go on the data that resulted from the actions
we took. The rest is the outcome of a lucubration exercise that is
beyond the scope of this thesis. In short, there is no secret formula
for ensuring that platforms are economically sustainable; the three
cases documented in this section are different in nature, yet all seem
to work and are generating their own actor–networks. Plainly there are
different models for how platforms, open or not, can become economically
sustainable over time.

### Obsolescence

We saw earlier in this section that sustainability as a concept is
linked to obsolescence when looking at the longevity of a platform. In
contemporary technology design, we are confronted by the concept of
*planned or programmed obsolescence*—in other words, the possibility of
deliberately programming the disappearance of a system (London 1932).
Both products and processes can become obsolete on the arrival of
something better, although the new does not necessarily eliminate the
old from the context of use: both the carpet sweeper and the vacuum
cleaner continue to co-exist in contemporary households, even if the
latter made the former obsolete (Nelson 1967). There are various reasons
for this. There may be government-policed technical obsolescence
programmed into infrastructure and services in order to increase their
capability, the classic example being the migration of analogue
television to digital terrestrial television. In recent years, analogue
has been wound up in all European countries (and many others), replaced
by the far more spectrum-efficient digital terrestrial television. This
change was programmed by the different countries and policed through
their institutions—public or private—dedicated to the management and
supervision of the telecommunications’ spectrum. In past years we have
seen this happen for many different technologies. Think only of the
migration of 2G telephony to 3G, and later 4G, and soon 5G. The way this
is enforced is typically by increasing taxes on the services that use
the old systems; what forces the enterprises offering the services to
switch to the newer technology also encourages users to migrate. Some
have argued that this degree of control, limiting obsolescence just to
keep the existing business models running, is counterproductive (Lessig
2001, 83). Nor is programmed obsolescence always immediately successful,
as seen in the case of GSM communication. This, as Nelson says, is ‘a
waste’, and not always a planned process at that. Indeed, obsolescence
can happen accidentally, much as the car made the traditional city
obsolete, because its streets, parking, and buildings were not designed
for the changes imposed on architecture by its arrival.

Obsolescence is a consequence of the techno-economic development of a
culture (Nelson 1967) and is wholly dependent on the historical moment
any given region is in. After the Second World War it was standard
practice the US, for example, when the country was capable of producing
and selling consumer products in huge quantities while still largely
investing in capital goods. Yet the term ‘planned obsolescence’ comes
from London (1932), and an essay in which he claimed it could be used to
keep production and consumption buoyant (London 1932). As Nelson (1967)
writes, obsolescence may not just be a consequence of technical
advances; it can be purely aesthetic. He uses the car industry as an
example, where users end up accepting a financial loss by purchasing the
new models that appear every year. Objects are obsolete from the moment
they are purchased, sometimes from the moment they are designed, and, in
some cases, even before the process of patenting an invention is
complete (Ackermann 2009, 195).

The philosopher Herbert Marcuse, with his critical view of capitalism,
takes a pessimistic line on obsolescence, explaining that it is part of
the system’s design and not an aberration (1969). He argues that its
*raison d’être* is the perpetuation of the ‘struggle for existence’. He
was investigating the idea of tolerance at the time, and referred to
obsolescence to show it cannot be considered a bad thing as long as it
is tolerated by consumers and producers. At the same time, tolerance
compels the consumer to get used to change and to plan for that change.
Lessig (2001), looking at the issue from a more liberal standpoint,
implies that planning for change is a handbrake on true innovation, for
he suggests that anything that forces technology to operate with a
planned obsolescence paradigm (as is the case with communication
spectrum policing) limits the chance of revolutionary technological
innovation (85). Lessig toys with the idea of removing not only
governmental regulation of the spectrum, but also market controls,
although he acknowledges that it might rapidly lead to the tragedy of
the commons.

There is another point to be made about obsolescence, which is the
extent it is determined by punctualization. There are systems that do
not necessarily become obsolete because of aging technology, but
because, having become ubiquitous and thus invisible, no one is
interested in them. Systems—tools and whole platforms even—may become
obsolete because we stop caring about them in a direct way, but this
obsolescence does not make them less needed. In effect, punctualization
brings with it an obsolescence of a cognitive nature: because we do not
see the tool, we do not perceive it as needed, and that remains the case
until something unexpected happens. Hence the OpenSSL ‘Heartbleed’
vulnerability detected in 2014, which affected the vast majority of
devices connected to the Internet (Synopsys Inc. 2014). There had been
an implementation bug in the wild for as long as three years until it
was found in 2014 in the OpenSSL library, a key component in the
encryption software that connects Linux and Windows computers to the
Internet. This meant that for an extended period malicious users could
have accessed encryption keys and protected user content. The software,
bugs and all, was so ubiquitous that everyone had taken it for granted
that it worked flawlessly. This was far from true, because there was no
one to take care of the necessary code updates—the OpenSSL project did
not have the financial resources for maintenance (Kaminsky 2014). The
bug in the OpenSSL library that unleashed the Heartbleed vulnerability
came about because of the lack of resources assigned to peer-review the
code that ran the system: once it was invisible, it was only a matter of
time before it became obsolete. This is also the issue in Adam’s
analysis of *delegation* (2005, 2008). In exploring the origins of an
ethics for things and the possibility of delegating moral decisions to
so-called moral agents in an actor–network, he notes that by delegating
we are giving responsibility for performing a task to either someone
else, or—as here—to a digital system. Delegating a task within an
actor–network can amount to an act of punctualization, because the full
complexity of that task disappears from view.

Probably the lesson to learn about obsolescence is that it is not always
a bad thing to implement it, and it does not necessarily conflict with
the idea of environmental sustainability or even product sustainability
(a.k.a. longevity). Obsolescence can also become a design strategy in
its own right; for example, if price is the determining factor in the
creation of an object or service, it might be convenient to use parts we
know will soon be obsolete as a way to reduce the cost to the end user.
It can even be a door onto a knowledge commons, for if there is no
further interest in making a profit from a technology, perhaps it could
be open-sourced, so that ecologies of repair and knowledge could be
built around it. All of which brings me to openness.

### Openness

I have already introduced the notion of openness as a design method with
various levels of application (Chapter 4). Concepts such as ‘radical
openness’ imply being open not only about results, but also about the
process of obtaining results and the designers’ intentions. This kind of
openness—embedded in the process—is predicated on co-creation processes
that engage users and designers (and eventually developers).
Participation, in that sense, would be fundamental to following an open
design process with an agenda that is rewritten as you go. This is what
Bratton (2015) mentions when discussing the creation of ‘platform
utopias’: we should ‘enable the appearance of programs that we cannot
already anticipate … in advance … a megastructuralism based on the
metaphor … of the atmosphere and on the scale and ubiquity of the
clouds’ (42). Back in the world of practicalities, I too have explored
how to handle openness, in my case using licences, and how the
automation of free and open licences has allowed for the development of
open design as praxis. I have already presented cases that are relevant
here, including Guifi.net or Debian, and of course Arduino, which is an
important part of many sections in this thesis.

The historian Paul N. Edwards, who has published on the creation of
technical platforms and infrastructure such as the military networks
that set the ground for the Internet as we know it or the global
infrastructure for weather monitoring and forecasting, takes yet another
view on openness in his book *The Closed World: Computers and the
Politics of Discourse in Cold War America* (1996). His interest is the
development of what he calls ‘the green world’, an open space where
actors try to come to terms with the world’s complexity through the
‘transcendence of rationality, authority, convention, and technology’.
Edwards’ green world broadens the perspective of sustainability to cover
environmental aspects. Platform designers will very rarely encounter a
world that is either entirely closed or completely open (green). It is
as if Edwards’ representations of the world are just extremes that we
will never reach. Will we ever, as a society, manage to achieve a
green-world scenario? Have we ever experienced such a time in human
history? Is the green world just a utopia, and we will always struggle
to reach it from our own closed version of the world?

There is yet another aspect to openness when dealing with the idea of
community: the curation of content on platforms. Who should determine
how content will be displayed on the platform? Who will control the
message? This leads to yet another form of closure, which Bratton calls
‘the disappearance of the outside’ that occurs when control of the
message is given to those who also control the platform. In talking
about Apple’s operating system strategy for mobile personal devices,
Bratton describes how ‘the walled garden of iOS … can also suffer from
having to serve as both platform and content at once’. This means that,
without the open curation of content, the platform itself becomes the
content and is made invisible. This happens to be a bidirectional
inference rule. Thus, by wanting to control the message and the way it
is delivered, Apple has to be closed: ‘the price of curation is closure’
(Bratton 2015, 46). Curation warrants further discussion when dealing
with communities, especially in the context of communities of learning.

Edwards’ green world (1996) is utopian, lateral, and invites
exploration, and he counterpoints it with a closed world that is
dystopian, vertical, and self-referential. To offer a simple explanation
of what, say, a vertical world is, in the market economy we talk of
segments or ‘verticals’, one of them being the Internet of things. The
vertical of always-connected, always-on devices and people—the IoT—spans
from the sensors doing the data-gathering all the way to the graphical
user interfaces presenting information. In the closed world, it is
imperative to own the whole vertical as a way to exercise control
(Bratton 2015); in the open world, devices are allowed to migrate from
one platform to the other thanks to open definitions of APIs, open
hardware definitions of devices, or open communication protocols (Brody
& Pureswaran 2014).

The study of the IoT as a platform involves a whole series of actors
operating in a multiplicity of networks, which are sometimes even
connected to other networks. In the IoT we find the discussion about
openness happens at all levels: from the technologies involved to the
data gathered, processed, and exchanged. Openness can be applied to both
the immaterial and the physical existence of the IoT, but also by
extension to other contexts (Herstatt & Ehls 2015, 20). The way we
regulate openness is through a series of licensing schemes (Chapter 4).
As Herstatt and Ehls mention in their book *Open Source Innovation*, ‘a
central element in all \[open\] approaches is collaboration on one
common valuable good … Most open-source projects are single-user
activities that probably could evolve to a flourish community’ (2015,
20). This is another relevant aspect of openness: its invitation to
collaborate. Although it is just an invitation, never an obligation.
Therefore, by establishing open design processes with open results, we
are inviting others to join in. Intentionality is crucial; however, it
will not guarantee that anyone will follow, nor that making something
open will ensure a community will form around it. The question is then
whether it is sustainable to have projects just because they are open,
even if they lack a community to either sustain them or embrace them. In
other words, does openness for the sake of openness make any sense?

Probably we can only answer that by looking at activism and politics, or
perhaps by trying to construct some sort of pre-emptive code of ethics.
Why would we be interested in having things open? Is it bad that
ultimately a company will profit from maintaining a proprietary system
that could be very beneficial for society? In light of current
circumstances in data usage and how it affects users, the answer may be
that we would prefer certain things not to happen. The issue with the
lack of openness in technological systems such as search algorithms,
control systems for self-driving cars, or encryption techniques is that
it is impossible to audit them. Without a peer review of the
technologies, how are we supposed to know that they are doing no harm?
How can we know that they are using state-of-the-art technology and not
obsolete, damaging technology? The example of OpenSSL Heartbleed shows
that even when something is open, a lack of resources makes impossible
to keep up with the necessary audits. These aspects centre on the need
to find strategies to make projects financially sustainable over time, a
variable that I called marketability and described earlier in this
chapter.

### <span id="anchor-2"></span><span id="anchor-3"></span><span id="anchor-2"></span>Ecology

This section deals with the concept of ecology as defined by two schools
of thought: actor–network theory and cybernetics. I have chosen two of
their main advocates to support my argument that the term ‘ecology’
should play a significant role in the creation of platforms. First,
representing actor–network theory is the sociologist Michelle Callon,
known as a leading proponent of actor–network theory and for his
contributions to the field of science and technology studies, and his
definition of networks; second, representing the cybernetics school, is
Klaus Krippendorff, an engineer and specialist in cybernetics, language,
and culture, who talks specifically about ecologies of artefacts leaving
the human as an external factor. Drawing on other authors such as Ehn, I
will argue that ecology is a fruitful word to apply to networks, as it
brings together actor–network theory and cybernetics.

The ecology of a system is defined by the way the system is
configured—the pieces, parts, people, mechanisms, locations, disposable
resources, indeed anything related to the system’s existence and the way
it is used define its ecology. The term builds upon Callon’s
techno-economic networks (1991), which he describes as a ‘coordinated
set of heterogeneous actors’ interacting to produce ‘methods for
generating goods and services’ (133). Actors are social beings which
relate through intermediaries. Both actors and intermediaries can be
human or non-human; what distinguishes between them is the authorship
role that actors assume versus the communicative role taken by
intermediaries. In a techno-economic network, intermediaries are
whatever defines the relationship between actors, while actors are the
ones in the network that possess authorship.

The ecology of a network, as I have defined it here, would thus include
all the actors and intermediaries in the network. What Callon (1991)
calls a network is in a sense what I call a platform. The ecology of a
platform therefore includes everything that acts as an interface between
its users, its developers, and its tools, as well as the tools
themselves. It is the boundary object that augments the actor–network.
As I have established, platforms are made of hardware, software, and
documentation, and are tied to a community of users involved to a
certain extent in the further improvement of the platform. The
platform’s ecology is thus all of those things: the objects, the
non-physical assets, the context, the developers, and the users.

In his 2005 book *The Semantic Turn*, Krippendorff introduces the
ecology of artefacts. He describes ecology as the interaction between
artefacts: how they relate to one another one-to-one or as part of a
group; whether the relationship extends over time (some artefacts are
the evolution of others); and how power is distributed within the
relationship (in a market economy, some artefacts are parasites on
others, as is the case with clones and copies). Later studies (Jung et
al. 2008) add empirical data to Krippendorff’s definition. Krippendorff
(2005) also explores the complexity and size of networked artefacts, and
how they supersede natural ecologies on both macro and micro levels.
Jung et al. concur with this understanding of ecology, noting that it
‘serves well both as a metaphor and as a theoretical construct to
support the examination of complex networks of interactive artefacts’
(2008, 201). One point where all these analyses differ from
actor–network theory is in considering the human factor in the ecology
of artefacts. People set the terms according to which artefacts interact
with one another, but are not part of the network—very different to the
techno-economic, sociomaterial networks envisaged by Callon (1991), or
Latour’s actor–network theory (2006). Indeed, Ehn (2007), in reviewing
*The Semantic Turn*, calls for Latour’s actor–network theory’s agency in
combination with Krippendorff’s ecology. I can only agree, for when
considering the term ‘ecology’ we need to have humans as part of the
sociotechnical assembly. Krippendorff seems to tiptoe around the human
factor conversation when he says that ‘ecologies of artefacts, even of
only moderate complexity, escape any one individual’s understanding’
(2005, 195), and he then moves on to possible classifications of
relationships between artefacts according to different perspectives.
Instead, I would argue that although I agree it is impossible to hope
for a bird’s-eye view of a system because of its size and the speed at
which interactions happen (as I explained in Chapter 4), it is this that
makes it imperative to consider people as part of the ecology, for our
interaction with the platform is shaped by the artefacts themselves and
their affordances, and vice versa. It is no more us humans controlling
them, the artefacts, as it is both of us integrated in an ecology of
bits and atoms with closed feedback loops (Wiener 1989 \[1950\]), where
the evolution and duration of the platform depends on our ability as
designers to participate in this always changing, strongly
interconnected (Bennett 2005), and highly dependent ecology of systems
and people. And a platform’s ability to engage anyone other than its
creators in daily interaction is manifest in its community, a term I
will examine next.

### Community

The term community touches upon some of the human aspects of the
assemblage. Feenberg (2007) (as discussed in Chapter 2), offers a simple
definition, describing the community as a world, an area of practice,
‘rather than a passively observed nature to which values are ascribed’
(28). Feenberg’s worlds are constructed through the connections between
actors, and are revealed by ‘everyday experience’. From Feenberg it is a
short step to Gillespie (2010), whose work I use to link communities and
platforms from a political perspective, looking at how platforms should
be ‘progressive’ and ‘egalitarian’. Gillespie states that communities
are governed by social contracts. These ideas—community through
participation and shared experiences, progressive (democratic) and
egalitarian governance, and social contracts—comprise the lens I use to
view platforms in order to gauge what we should consider when studying
(or forming) communities augmented by platforms. In this case, I do not
stop at observations, as in Chapter 2, but dig deeper to measure those
ideas against experience, to answer the question of whether the whole is
greater than the sum of its parts.

Hippel (2005, 11) talks about user innovation communities, where users
join together in networks ‘that provide useful structures and tools for
their interactions and for the distribution of innovations’. A
specialist in communities of innovation—groups of people who meet to
share knowledge and innovate within certain sectors—Hippel lists the
advantages that communities of innovation have over more traditional
business models: speedier testing, dissemination, and the construction
of larger systems through the creation of ‘interlinkable modules created
by community participants’ (11). This highlights one of the reasons why
modularity is relevant to platform creation, as it allows for a better
way for community members to contribute, with more feasible goals than
if they faced large monolithic bodies of work. The Debian case I
mentioned earlier is a good example of how modularity enables a
community of developers to form around solving a complex technical task
(Corbet et al. 2012; Corbet & Kroah-Hartman 2017; Linux Foundation
2018). Organizing the work around a platform like Debian requires that
the product itself, the software, be structured in a way that can be
simultaneously modified by thousands of participants, the community. The
platform is built around the idea of having groups of people
simultaneously modifying text files that are strongly interconnected
that a modification to one of them can affect the proper functioning of
another. Such a community requires a governance model, a decision
mechanism, and a series of technical tools specially created to speed up
decision-making and the evaluation of contributions. Modularity is
therefore at the very heart of the Debian community.

Going back to Hippel (2001, 83) and his work on innovation communities,
he shows how even if in market terms it might not make sense to consider
the existence of user innovation communities with the ability to
innovate and compete with established market giants, the empirical data
proves otherwise. Beyond innovation, another aspect that a community
could tackle is dissemination in the form of knowledge-sharing. For
communities of individuals this is related to openness, as described
earlier in this chapter. Hippel notes that the rewards for revealing
innovations within a community are ‘improved reputations, expected
reciprocity, and helping to build a community’ (86). The role of the
platform in this case is to enable community-sharing innovations,
because in Hippel’s terms sharing will de facto build the community.

But how can a community be designed? What comes first, the community or
the platform? What do designers deal with, the community per se or the
process of enabling the community to happen? In his essay ‘The Future Is
Not What It Used To Be’, the designer and architect Victor Papanek
reflects on how the ‘function of a community … is to act as a goal, not
as a passage point; an end, not a means; a stop, not a flow’ (1988, 13).
Although he is talking about communities from an urban planning
perspective, there are lessons to be learnt from his essay that can be
applied to platform design. When Papanek talks about ‘community design’,
he describes how a successful approach is the one that that puts ‘all
the talent’ into creating the shared spaces, the so-called ‘communal
nucleus’, and with that in place the rest of the system will follow.

One clear difference between Papanek’s empirical data (1988) and my own
experience is the size of the community. The size of his ideal
community—always talking about people sharing a common space—was some
500 people. Many online platforms today with so few users would not be
considered sustainable. It is as if the dematerialization of human
relationships in the network forces the need for a great many more users
to compensate for the lack of physical substance, or, as Bratton puts
it, the new utopian (city) designs are islands (closed communities) that
offer ‘centralized economy of scale and density for the consumption of
resources’ (2015, 41). Bratton’s ‘Stack’, a sort of global actor–network
that has swallowed all the other networks and relationships, will
‘support mega-dense resource economies’, which in turn will drive the
creation of larger self-contained communities. Bratton’s reference to
density can be read in purely physical terms as the number of users,
participants, or active contributors to the same communal resource, but
it could also have a more cognitive meaning as the ratio of signal to
noise, or the quality of the contributions to the community. As Geipel
et al. (2014) mention in their survey of a hundred open-source
communities, it is not just the number of users in a community that
matters, it is the quality. Geipel et al. studied SourceForge, a
repository of open-source projects, and thus had to establish their own
evaluation criteria for quality. This is another lesson to learn when
working with platforms, given their ad hoc nature (they are defined by
the interaction of users and developers over time): quality criteria are
metrics that must be negotiated within the network. And that negotiation
will have to continue for as long as the platform exists.

In addition to the ideas unpacked in this section—modularity, density,
and sharing—which all have to do with community, there are two main
aspects that I have dealt with in separate subsections:
democracy—understood as technological empowerment—and the
political—looking at governance and the political implications of
platforms.

### <span id="anchor-4"></span>Democracy as tech empowerment

Alexander et al.’s concept of democracy (1977, 71–4) as enacted through
the decentralization of power in communities, if applied to the specific
situation of a socio-technological arrangement intended to build a
community of co-learning in which participants educate one another by
sharing experiences, participating in the discourse, and eventually
contributing to the further development of the platform, makes it clear
that in doing so novice users will have to be empowered by the
platform’s technology in order to become active participants. This
process of democratically creating technologies, expressed as a
necessity by Feenberg (2010) (see Chapter 2), has been challenged both
directly and indirectly by a number of designers. In this section I will
suggest counterarguments to Alexander et al.’s hypothesis, and reflect
on how I enacted this democratization (rather than a democratic process)
in a variety of projects.

Earlier in this chapter I introduced Papanek’s communal nucleus (1988),
which at first sight seems to be at risk of the classic issue of control
exercised by the centre on the periphery, as explained, for example, in
Law’s study (1986) of Portuguese shipping in the early modern period.
However, I believe that we need to make a distinction between the
technical infrastructure and the actual actor–network, the platform,
which we the designers and users want to construct on top of it. This is
something covered in Saldana et al.’s paper (2016), which demonstrates
some of the ways to pursue a network architecture, including some cases
that are fully distributed. The Guifi.net case by Baig et al. (2016)
illustrates how, by using the standard pieces described by Raghavan et
al. (2017), it would be possible novices to participate in the
construction of a network. However, in other platforms such as Arduino
that have millions of users, the actual technical infrastructure is
centralized with a single cloud provider. The computer architecture
supporting it is distributed, but not in the way Alexander et al. (1977)
suggest. I would argue that there are four possible combinations: the
technical construction, distributed or not; and the platform governance,
distributed or not.

It should be noted as well that the categorization of the distribution
of governance cannot be defined having a binary ‘yes/no’ answer. There
are different levels of how to distribute and enact power among the
members of a community. This is something that Raymond registered in his
book *The Cathedral and the Bazaar* (1999), which is mandatory reading
for anyone interested in how an open-source software community works. In
the Debian case, there is a clear hierarchy defined as the ‘benevolent
dictator’ scenario (Raymond 1999, 101) where the whole community agrees
to that a single person will take the final decision on whether
technical patches are applied to the technology or not. Some other
projects, such as Arduino, have a team of people applying the patches;
they are either developers hired by the Arduino company or developers
from sister communities that benefit from having a development
environment (the Arduino IDE) to program their own hardware designs.
Others have a fully distributed mechanism for deciding how to apply
patches. Geipel et al. (2014) note the various models for command in a
community of software creation: communication within the community may
be centralized to a group of highly influential users and developers,
and even if a high turnover in users is important for a community around
a platform, it is even more important that those contributing can join
in improving the tools and documentation for the newcomers that join.
Figuring out which is the best model to adopt in order to achieve the
platform’s development and survival is then a design decision. It is the
ethos of the project that will eventually determine this aspect. As Ehn
(1988, 407) puts it, ‘The role … skill and democracy \[have\] in
work-oriented design is as consciously articulated values on which
design should be based.’

In all these cases, there is a learning curve for community
participants: no one can join one day and be elevated to benevolent
dictator the next. Communities such as the ones presented here are
meritocracies. Nevertheless, merit can only be obtained through active
participation in the community, and that means participants have to
learn how it works. For the platform’s own survival, the technical
empowerment of users is essential, if only as a strategy to help novices
find their feet.

There is another discussion to be continued from Chapter 2 about whether
an algorithm is or is not a tool. Relevant here is the question of the
democratic element in designing a platform, given that algorithms are
somehow part of its creation. If software platforms are defined by
algorithms, access to the processes they cover is needed for the
creation, tweaking, and maintenance of the platform. There are examples
where the algorithm is of vital importance for participation in a
platform—Google’s search algorithm, which commands all interactions with
the platform, for example. Google, the people who make searches, the
people who try to boost their websites in the search rankings, the bots
that who try to do the same: they compose an interesting assemblage of
humans and non-humans. The reason to interact with the platform is
either to look for something or to try to improve one’s ranking. While
the search operation is simple (it still requires certain level of skill
to write the queries that will guide you to the best possible
responses), the business of trying to improve your rankings calls for a
series of techniques—search engine optimization (SEO)—that are not
simple. In that sense, participants have no power to influence the
algorithm, and they are subject to decisions made by an entity that
controls the platform. The interesting point, as Rouvroy (2013) notes,
is that not even the engineers running the platform know exactly how the
algorithm works. So the question remains, how will democracy be enacted
on platforms where algorithms or other non-humans play a vital role in
how relationships are established between actors?

### The political

Latour (2006, 250), talking about the possibility of change that a
certain strategy may offer in the current state of (political) affairs,
concludes that ‘only if forces are made of smaller ties, whose
resistance can be tested one by one, … you might have a chance to modify
a given state of affairs’.^[^17^](#fn17){#fnref17 .footnoteRef}^ As
designer I read this to mean that if we want our design processes,
artefacts, and services to have a meaningful impact, we may as well
think big but act small. This seems to be in line with Alexander et
al.’s model (1977, 71–4) of distributed governance, as presented in the
previous section, where democratization is explained as the process of
decentralizing power to smaller units or communities. To an extent this
feels as if the idea of disintermediation from Chapter 2 (Raghavan et
al. 2017) is being applied to political representatives—and why should
someone deal with a remote administration to solve local issues? The
process of intermediation in this case seems counterintuitive. The
impression is that Alexander et al.’s communities would do very well
with Latour’s leaders (or engaged assemblies), practising active
politics locally.

Also in *A Pattern Language*, Alexander et al. infer that nothing can be
built in isolation: the action of building has to repair the world
around it and within it, making the world more coherent (1977, xiii).
This is a very political view of design, since it assumes there is an
intention to do good, that a certain ethos is part of designing. And
since design is meant to be done collectively, the ethos should be a
constitutive property (or feature) of the community, and, by extension,
of the platform supporting it. Linking this idea of doing good with the
idea of education, and even with governance, we find Freire’s *Pedagogy
of the oppressed* (2005), which suggests that the measurable goal of the
education process is the ability to think-transform, and that such a
goal is best pursued by reflection in action. Freire introduces his
version of ‘dialogics’ as a form of education conducted by dialogue,
which turns into a practice of freedom. Education, when properly
conducted, becomes a way to make everyone equal. Since technology is not
neutral, the intention to educate in the creation of a platform is an
attempt to do good—an attempt to practise freedom.

Other authors are concerned about the use that commercial platforms make
of politics to obtain direct or indirect financial advantages. This
boils down to the question of how to balance marketability and other
values. In Gillespie’s paper ‘The politics of “platforms”’ (2010) he
looks at the story of YouTube and its role as enabler of freedom of
speech, but also as an uncurated place where offences can be committed
under the umbrella of that same freedom of speech. Gillespie shows that
both positions can easily be masked by a protective layer of discourse,
in which the term ‘platform’ plays a significant role. In much the same
way, companies such as Google are working politically—through
lobbyists—but also ‘discursively to frame their services and
technologies’ (348). According to Gillespie, this is an example of how
service providers use language to convey an attractive picture of their
offerings, appealing in terms that go beyond pure business to impinge on
other contexts, such as human rights.

Latour defines a new form of politics, separate from critical sociology,
and names it the ‘modern constitution’. It is ‘the redefinition of
politics as the progressive composition of the common world’ (Latour
2006, 254), readily applied to the assemblages of society and nature at
once. Latour wishes to construct the politics of actor–networks in such
a way as to take both humans and non-humans into consideration. He
claims that the controversies about what makes the social world should
be solved by the participants, not by social scientists. Latour’s
political take on agency is that participants should be the ones in
control of the situation.

In looking at the political aspects of communities, I have concentrated
on two main topics: the idea that politics is about involvement in the
governance of the community; and the idea that politics is about
understanding the context when making decisions, which would lead not to
the most comfortable choices, but to those that will be best for
everyone (including those outside the community).

Summary
-------

This chapter charts the lessons learnt in the course of my research,
from the more theoretical to the more practical. To elucidate both the
concepts and the contexts where they unfold, I sequence the appearance
of the ‘functional requirements’ I would argue must be investigated when
designing new platforms, and then detail the requirements themselves by
function, thematizing the papers in the compilation along with other
projects I have worked on.

The functional requirements are arranged in an order that displays the
transition from more techno-deterministic concepts—sustainability—to
those closer to collaborative action and concepts such as co-learning,
collaborative work, and community. The outcome of the chapter is a
series of discursive tools that platform designers can add to their
personal toolboxes, to use when co-designing new platforms for
sociotechnical assemblages involving humans and non-humans. The concepts
constitute an actor–network of sorts, where the various terms
(sustainability, obsolescence, openness, ecology, and community) are the
interlinked nodes—for these concepts cannot survive in isolation.
Therefore, I suggest weighing each one carefully when designing, even
though, as I mentioned earlier, there is no specific order in which to
apply them, and there might not be a need to use all of them in all
phases of a project.

<div class="footnotes">

------------------------------------------------------------------------

1.  <div id="fn1">

    </div>

    Before starting at Malmö University in 2000, I worked as microchip
    designer at Infineon in Munich, Germany. I had the opportunity to
    visit their Dresden facilities, a factory constructed on a field
    that was used as a tank cemetery at the end of the Second World War.
    The site was built in record time by thousands of builders working
    round the clock. Such a facility is always in operation to maximize
    the return on the investment needed to start it. [↩](#fnref1)

2.  <div id="fn2">

    </div>

    The indoor location system, which went by the name of PISHA
    (Positioning Indoor System of High Accuracy), was used in one of the
    ‘Micromobility and Learning’ experiments to track people’s movements
    in the open spaces at the School of Arts and
    Communication.[↩](#fnref2)

3.  <div id="fn3">

    </div>

    In 2003, rather than the IoT we used to talk about WSN—wireless
    sensor networks—which preceded the IoT by several years. From the
    beginning the indoor location system was meant to be a special
    instantiation of a WSN, a network where the various active moving
    wireless devices could be located by other wireless static
    devices.[↩](#fnref3)

4.  <div id="fn4">

    </div>

    We had in our hands a tool that could localize objects in the three
    dimensions of space, at a refresh rate of 10 times a second and with
    an accuracy of 5 centimetres, using the equivalent of a satellite
    system such as GPS or Galileo, but for indoor use.[↩](#fnref4)

5.  <div id="fn5">

    </div>

    Open source hardware did not count in the legal framework in 2005,
    when we were all but finished working actively with the indoor
    location system; now it does count, making it harder to find support
    for the project among institutions or companies.[↩](#fnref5)

6.  <div id="fn6">

    </div>

    At time of writing, some companies are starting to offer services
    using indoor maps for public spaces and the like, while
    technological developments, mainly in Ultra-Wideband, make indoor
    positioning small enough to be used in all sorts of everyday
    applications.[↩](#fnref6)

7.  <div id="fn7">

    </div>

    The first open hardware journal was *HardwareX* by
    Elsevier (https://www.journals.elsevier.com/hardwarex/) and did not
    appear until 2015.[↩](#fnref7)

8.  <div id="fn8">

    </div>

    Not only did we not anticipate the success of Arduino, we did not
    foresee its appeal for people who were not our intended
    primary users. For some people, Arduino has become their main source
    of revenue, as I explained in my essay ‘The Power of the Copy of the
    Copy’ (Cuartielles 2011); for others it was the path to a career in
    engineering; and there are people making machines to improve their
    daily lives by automating simple tasks, etc.[↩](#fnref8)

9.  <div id="fn9">

    </div>

    Token-ring is a networking technique whereby all the devices are
    arranged in a circular configuration. Each device can only
    communicate with the one on the left or the one on the right. In
    order to send a message to any device in the network, the
    information packages have to travel through a sequence of other
    devices to the receiver. Communication is only one-way, so that even
    if a device could technically communicate in two directions, it will
    only do so in one. The name ‘token-ring’ comes from the circular
    shape of the network and from the fact that, in order to determine
    which device has the right to send data, the devices pass around a
    digital token that gives them the right to occupy the
    channel.[↩](#fnref9)

10. <div id="fn10">

    </div>

    ‘Creative Technologies in the Classroom’, which brings technology
    teachers up to speed with contemporary educational tools, is a
    project I designed for the Arduino company, sponsored by the
    foundations ‘Fundacion Telefonica’ and ‘Fundacion Bancaria La Caixa’
    in 2013, and an official Arduino product as of 2018.[↩](#fnref10)

11. <div id="fn11">

    </div>

    The SandS project paved the way for the creation of the Arduino Yun
    board, which sold well because of its innovative approach to offer
    connectivity to the Internet as well as low-level control of
    physical drivers for latency sensitive devices such as motors. For
    the Arduino Yun, Arduino was awarded the Innovation Luminary Award
    by the European Commission in 2017.[↩](#fnref11)

12. <div id="fn12">

    </div>

    The PELARS toolkit is still being used for user trials by
    researchers at Malmö University, long after the final deliverable of
    the project. It is as yet unclear whether this design will become
    a product. Arduino tried to speed up the process by launching a
    crowdfunding campaign that did not go ahead for reasons that were
    purely financial—the sum needed for the project to be viable was
    larger than the community was ready to support.[↩](#fnref12)

13. <div id="fn13">

    </div>

    The metrics of how to measure satisfaction vary depending on the
    context and circumstances. For developers, satisfaction comes from
    their work being appreciated by users; for users, if the system
    works as expected; for all, if a system functions as long as it is
    needed.[↩](#fnref13)

14. <div id="fn14">

    </div>

    Based on this premise, various vendors are still manufacturing
    boards including GSM modems—for example, Arduino launched its MKR
    GSM board in 2017 to leverage GSM connectivity for as long as it
    exists, which could be several years.[↩](#fnref14)

15. <div id="fn15">

    </div>

    Push, pull, commit, add: all are common terms in the software world,
    being the basic commands for sharing code in Git, the open-source
    software used to co-create software applications with the
    collaboration of thousands of contributors. ‘Push’ refers to the
    command to send one’s code to the shared repository.[↩](#fnref15)

16. <div id="fn16">

    </div>

    Stallman 2002, 44: ‘Thus, you may have paid money to get copies of
    free software, or you may have obtained copies at no charge. But
    regardless of how you got your copies, you always have the freedom
    to copy and change the software, even to sell copies. *Free
    software* does not mean *non-commercial*. A free program must be
    available for commercial use, commercial development, and
    commercial distribution. Commercial development of free software is
    no longer unusual; such free commercial software is very
    important.’[↩](#fnref16)

17. <div id="fn17">

    </div>

    Latour (2006): ‘if you have to fight against a force that is
    invisible, untraceable, ubiquitous, and total, you will be powerless
    and roundly defeated. It’s only if forces are made of smaller ties,
    whose resistance can be tested one by one, that you might have a
    chance to modify a given state of affairs. To put it bluntly: if
    there is a society, then no politics is possible.’[↩](#fnref17)

</div>
